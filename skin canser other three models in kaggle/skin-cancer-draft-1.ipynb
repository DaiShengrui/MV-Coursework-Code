{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":505351,"sourceType":"datasetVersion","datasetId":174469},{"sourceId":3808264,"sourceType":"datasetVersion","datasetId":2259678},{"sourceId":5424506,"sourceType":"datasetVersion","datasetId":3058676}],"dockerImageVersionId":30350,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\n%matplotlib inline\nimport matplotlib.colors as colors\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nimport seaborn as sns\nfrom PIL import Image\nnp.random.seed(11) #random number\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nimport itertools\nimport cv2\nimport skimage.color\nimport skimage.filters\nfrom skimage import io, exposure, morphology, filters, color, segmentation, feature, measure, img_as_float, img_as_ubyte\nfrom skimage.segmentation import chan_vese\nfrom skimage.measure import label, regionprops\nimport math\nfrom PIL import Image, ImageChops, ImageStat\n!pip install extcolors\nimport extcolors","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:29:18.182814Z","iopub.execute_input":"2023-04-15T20:29:18.183261Z","iopub.status.idle":"2023-04-15T20:29:32.602903Z","shell.execute_reply.started":"2023-04-15T20:29:18.183174Z","shell.execute_reply":"2023-04-15T20:29:32.601565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Dropout, LSTM, Embedding, Reshape, GlobalAveragePooling2D\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n\nfrom keras import backend as K\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n# add other models as required\nfrom keras import backend as K \n\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_recall_fscore_support as score, precision_score, recall_score, f1_score\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.feature_selection import RFECV\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier, Pool\n\nimport pickle\nfrom tensorflow.keras.utils import plot_model\nfrom keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:29:32.607288Z","iopub.execute_input":"2023-04-15T20:29:32.608167Z","iopub.status.idle":"2023-04-15T20:29:38.935919Z","shell.execute_reply.started":"2023-04-15T20:29:32.60812Z","shell.execute_reply":"2023-04-15T20:29:38.935009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 2 : Loading pictures and making Dictionary of images and labels**\n\nIn this step I load in the pictures and turn them into numpy arrays using their RGB values. As the pictures have already been resized to 224x224, there's no need to resize them. As the pictures do not have any labels, these need to be created. Finally, the pictures are added together to a big training set and shuffeled.","metadata":{}},{"cell_type":"code","source":"folder_benign_train = '/kaggle/input/skin-cancer-malignant-vs-benign/train/benign'\nfolder_malignant_train = '/kaggle/input/skin-cancer-malignant-vs-benign/train/malignant'\n\nfolder_benign_test = '/kaggle/input/skin-cancer-malignant-vs-benign/test/benign'\nfolder_malignant_test = '/kaggle/input/skin-cancer-malignant-vs-benign/test/malignant'\n\nread = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:29:38.937434Z","iopub.execute_input":"2023-04-15T20:29:38.938112Z","iopub.status.idle":"2023-04-15T20:29:38.943369Z","shell.execute_reply.started":"2023-04-15T20:29:38.938077Z","shell.execute_reply":"2023-04-15T20:29:38.942118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load in training pictures \nims_benign = [read(os.path.join(folder_benign_train, filename)) for filename in os.listdir(folder_benign_train)]\nX_benign = np.array(ims_benign, dtype='uint8')\nims_malignant = [read(os.path.join(folder_malignant_train, filename)) for filename in os.listdir(folder_malignant_train)]\nX_malignant = np.array(ims_malignant, dtype='uint8')","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:29:38.947576Z","iopub.execute_input":"2023-04-15T20:29:38.948309Z","iopub.status.idle":"2023-04-15T20:29:59.116098Z","shell.execute_reply.started":"2023-04-15T20:29:38.948253Z","shell.execute_reply":"2023-04-15T20:29:59.114961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_benign.shape)\nprint(X_malignant.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:29:59.117481Z","iopub.execute_input":"2023-04-15T20:29:59.117828Z","iopub.status.idle":"2023-04-15T20:29:59.123607Z","shell.execute_reply.started":"2023-04-15T20:29:59.117797Z","shell.execute_reply":"2023-04-15T20:29:59.121379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load in testing pictures\nims_benign = [read(os.path.join(folder_benign_test, filename)) for filename in os.listdir(folder_benign_test)]\nX_benign_test = np.array(ims_benign, dtype='uint8')\nims_malignant = [read(os.path.join(folder_malignant_test, filename)) for filename in os.listdir(folder_malignant_test)]\nX_malignant_test = np.array(ims_malignant, dtype='uint8')","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:29:59.124894Z","iopub.execute_input":"2023-04-15T20:29:59.125248Z","iopub.status.idle":"2023-04-15T20:30:04.596472Z","shell.execute_reply.started":"2023-04-15T20:29:59.125218Z","shell.execute_reply":"2023-04-15T20:30:04.595363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create labels\ny_benign = np.zeros(X_benign.shape[0])\ny_malignant = np.ones(X_malignant.shape[0])\n\ny_benign_test = np.zeros(X_benign_test.shape[0])\ny_malignant_test = np.ones(X_malignant_test.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:30:04.597931Z","iopub.execute_input":"2023-04-15T20:30:04.598266Z","iopub.status.idle":"2023-04-15T20:30:04.604875Z","shell.execute_reply.started":"2023-04-15T20:30:04.598237Z","shell.execute_reply":"2023-04-15T20:30:04.603626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge data \nX_train = np.concatenate((X_benign, X_malignant), axis = 0)\ny_train = np.concatenate((y_benign, y_malignant), axis = 0)\n\nX_test = np.concatenate((X_benign_test, X_malignant_test), axis = 0)\ny_test = np.concatenate((y_benign_test, y_malignant_test), axis = 0)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:30:04.606288Z","iopub.execute_input":"2023-04-15T20:30:04.606606Z","iopub.status.idle":"2023-04-15T20:30:04.878304Z","shell.execute_reply.started":"2023-04-15T20:30:04.606577Z","shell.execute_reply":"2023-04-15T20:30:04.8774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:04:27.003657Z","iopub.execute_input":"2023-04-15T18:04:27.004098Z","iopub.status.idle":"2023-04-15T18:04:27.010728Z","shell.execute_reply.started":"2023-04-15T18:04:27.004061Z","shell.execute_reply":"2023-04-15T18:04:27.0098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffle data\n# dataset already shuffled\n'''\ns = np.arange(X_train.shape[0])\nnp.random.shuffle(s)\nX_train = X_train[s]\ny_train = y_train[s]\n\ns = np.arange(X_test.shape[0])\nnp.random.shuffle(s)\nX_test = X_test[s]\ny_test = y_test[s]\n'''","metadata":{"execution":{"iopub.status.busy":"2023-03-31T18:59:10.024363Z","iopub.execute_input":"2023-03-31T18:59:10.025295Z","iopub.status.idle":"2023-03-31T18:59:10.05525Z","shell.execute_reply.started":"2023-03-31T18:59:10.025183Z","shell.execute_reply":"2023-03-31T18:59:10.05426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**imshow_all()** allows to plot a series of images side-by-side using matplotlib.","metadata":{}},{"cell_type":"code","source":"def imshow_all(*images, **kwargs):\n    \"\"\"\n    Plot a series of images side-by-side.\n\n    Convert all images to float so that images have a common intensity range.\n\n    Parameters\n    ----------\n    limits : str\n        Control the intensity limits. By default, 'image' is used set the\n        min/max intensities to the min/max of all images. Setting `limits` to\n        'dtype' can also be used if you want to preserve the image exposure.\n    titles : list of str\n        Titles for subplots. If the length of titles is less than the number\n        of images, empty strings are appended.\n    kwargs : dict\n        Additional keyword-arguments passed to `imshow`.\n    \"\"\"\n    images = [img_as_float(img) for img in images]\n\n    titles = kwargs.pop('titles', [])\n    if len(titles) != len(images):\n        titles = list(titles) + [''] * (len(images) - len(titles))\n\n    limits = kwargs.pop('limits', 'image')\n    if limits == 'image':\n        kwargs.setdefault('vmin', min(img.min() for img in images))\n        kwargs.setdefault('vmax', max(img.max() for img in images))\n    elif limits == 'dtype':\n        vmin, vmax = dtype_limits(images[0])\n        kwargs.setdefault('vmin', vmin)\n        kwargs.setdefault('vmax', vmax)\n\n    nrows, ncols = kwargs.get('shape', (1, len(images)))\n    \n    axes_off = kwargs.pop('axes_off', False)\n\n    size = nrows * kwargs.pop('size', 5)\n    width = size * len(images)\n    if nrows > 1:\n        width /= nrows * 1.33\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(width, size))\n    for ax, img, label in zip(axes.ravel(), images, titles):\n        ax.imshow(img, **kwargs)\n        ax.set_title(label)\n        ax.grid(False)\n        if axes_off:\n            ax.set_axis_off()\n    fig.savefig('images.png', dpi = 300)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:30:16.542805Z","iopub.execute_input":"2023-04-15T20:30:16.543216Z","iopub.status.idle":"2023-04-15T20:30:16.556905Z","shell.execute_reply.started":"2023-04-15T20:30:16.543184Z","shell.execute_reply":"2023-04-15T20:30:16.555711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dullrazor(img, showimgs, lowbound=15, filterstruc=3, inpaintmat=3):\n    \n    #grayscale\n    imgtmp1 = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n\n    #applying a blackhat\n    filterSize =(filterstruc, filterstruc)\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, filterSize) \n    imgtmp2 = cv2.morphologyEx(imgtmp1, cv2.MORPH_BLACKHAT, kernel)\n\n    #0=skin and 255=hair\n    ret, mask = cv2.threshold(imgtmp2, lowbound, 255, cv2.THRESH_BINARY)\n    \n    #inpainting\n    img_final = cv2.inpaint(img, mask, inpaintmat ,cv2.INPAINT_TELEA)\n    \n    \n    if showimgs:\n        fig=plt.figure(figsize=(24, 16))\n        columns = 5\n        rows = 1\n        \n        fig.add_subplot(rows, columns, 1)\n        plt.imshow(img, interpolation='nearest')\n        \n        fig.add_subplot(rows, columns, 2)\n        plt.imshow(imgtmp1, cmap=\"gray\")\n        \n        fig.add_subplot(rows, columns, 3)\n        plt.imshow(imgtmp2, cmap='gray')\n        \n        fig.add_subplot(rows, columns, 4)\n        plt.imshow(mask, cmap='gray')\n        \n        fig.add_subplot(rows, columns, 5)\n        plt.imshow(img_final)\n        print(\"___________________\")\n\n\n    return img_final","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:30:19.321693Z","iopub.execute_input":"2023-04-15T20:30:19.322095Z","iopub.status.idle":"2023-04-15T20:30:19.331253Z","shell.execute_reply.started":"2023-04-15T20:30:19.322063Z","shell.execute_reply":"2023-04-15T20:30:19.330428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_test = read(os.path.join(\"/kaggle/input/skin-cancer-malignant-vs-benign/test/malignant/\", \"1012.jpg\"))\nimg_test_array = np.array(img_test, dtype='uint8')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img_test_array, interpolation='nearest')\nplt.savefig('sample.png', dpi = 300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:23:44.939379Z","iopub.execute_input":"2023-04-15T18:23:44.93976Z","iopub.status.idle":"2023-04-15T18:23:45.309337Z","shell.execute_reply.started":"2023-04-15T18:23:44.93973Z","shell.execute_reply":"2023-04-15T18:23:45.308402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_p1 = dullrazor(img_test_array,showimgs=True)\nplt.imshow(img_p1, interpolation='nearest')\nplt.savefig('dullrazor.png', dpi = 300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:04:54.022386Z","iopub.execute_input":"2023-04-15T18:04:54.022785Z","iopub.status.idle":"2023-04-15T18:04:57.090248Z","shell.execute_reply.started":"2023-04-15T18:04:54.022752Z","shell.execute_reply":"2023-04-15T18:04:57.089397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(48, 32))\ncolumns = 2\nrows = 1\n\nimg_p2 = cv2.fastNlMeansDenoisingColored(img_p1,None,2,2,7,21)\n\nfig.add_subplot(rows, columns, 1)\nplt.imshow(img_p1, interpolation='nearest')\n\nfig.add_subplot(rows, columns, 2)\nplt.imshow(img_p2, interpolation='nearest')\nfig.savefig('fastNl.png', dpi = 300)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:11:03.696555Z","iopub.execute_input":"2023-04-15T18:11:03.696995Z","iopub.status.idle":"2023-04-15T18:11:13.830605Z","shell.execute_reply.started":"2023-04-15T18:11:03.696962Z","shell.execute_reply":"2023-04-15T18:11:13.829273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import skimage.color\nimport skimage.filters\ngray_image = skimage.color.rgb2gray(img_p2)\nplt.imshow(gray_image, cmap=\"gray\")\nplt.savefig('bg.png', dpi = 300)\n\n# show the histogram of the gray-scaled image\nhistogram, bin_edges = np.histogram(gray_image, bins=256, range=(0.0, 1.0))\nfig, ax = plt.subplots()\nplt.plot(bin_edges[0:-1], histogram)\nplt.title(\"Graylevel histogram\")\nplt.xlabel(\"gray value\")\nplt.ylabel(\"pixel count\")\nplt.xlim(0, 1.0)\nplt.savefig('histo.png', dpi = 300)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:12:46.743862Z","iopub.execute_input":"2023-04-15T18:12:46.744301Z","iopub.status.idle":"2023-04-15T18:12:47.492488Z","shell.execute_reply.started":"2023-04-15T18:12:46.744262Z","shell.execute_reply":"2023-04-15T18:12:47.49138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The histogram has a peaks starting from 0.2 to a little more than 0.8, with a significant peak around 0.6. Thus, this image is a good candidate for thresholding with Otsu’s method. The outcome is that Otsu’s method finds a threshold value between the two peaks of a grayscale histogram.\n\nThe skimage.filters.threshold_otsu() function can be used to determine the threshold automatically via Otsu’s method. Then numpy comparison operators can be used to apply it as before. ","metadata":{}},{"cell_type":"code","source":"# perform automatic thresholding\nt = skimage.filters.threshold_otsu(gray_image)\nprint(\"Found automatic threshold t = {}.\".format(t))","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:13:28.516767Z","iopub.execute_input":"2023-04-15T18:13:28.517154Z","iopub.status.idle":"2023-04-15T18:13:28.539294Z","shell.execute_reply.started":"2023-04-15T18:13:28.517128Z","shell.execute_reply":"2023-04-15T18:13:28.53777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For this root image and a Gaussian blur with the chosen sigma of 1.0, the computed threshold value is 0.58. No we can create a binary mask with the comparison operator <. As we have seen before, pixels above the threshold value will be turned on, those below the threshold will be turned off.\n\n","metadata":{}},{"cell_type":"code","source":"# create a binary mask with the threshold found by Otsu's method\nbinary_mask = gray_image < t\n\nfig, ax = plt.subplots()\nplt.imshow(binary_mask, cmap=\"gray\")\nplt.savefig('mask.png', dpi = 300)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:13:31.625642Z","iopub.execute_input":"2023-04-15T18:13:31.62599Z","iopub.status.idle":"2023-04-15T18:13:32.003641Z","shell.execute_reply.started":"2023-04-15T18:13:31.625966Z","shell.execute_reply":"2023-04-15T18:13:32.002282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we use the mask to select the foreground:","metadata":{}},{"cell_type":"code","source":"# apply the binary mask to select the foreground\nselection = img_p2.copy()\nselection[~binary_mask] = 0\n\nfig, ax = plt.subplots()\nplt.imshow(selection)\nplt.savefig('mask_2.png', dpi = 300)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:13:55.955653Z","iopub.execute_input":"2023-04-15T18:13:55.956064Z","iopub.status.idle":"2023-04-15T18:13:56.495314Z","shell.execute_reply.started":"2023-04-15T18:13:55.956031Z","shell.execute_reply":"2023-04-15T18:13:56.494548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#image = img_as_float(data.camera())\n# Feel free to play around with the parameters to see how they impact the result\nimage = skimage.color.rgb2gray(selection)\ncv = chan_vese(image, mu=0.5, lambda1=1, lambda2=1, tol=1e-3, max_num_iter=200,\n               dt=0.5, init_level_set=\"checkerboard\", extended_output=True)\n\nfig, axes = plt.subplots(2, 2, figsize=(8, 8))\nax = axes.flatten()\n\nax[0].imshow(image, cmap=\"gray\")\nax[0].set_axis_off()\nax[0].set_title(\"Original Image\", fontsize=12)\n\nax[1].imshow(cv[0], cmap=\"gray\")\nax[1].set_axis_off()\ntitle = \"Chan-Vese segmentation - {} iterations\".format(len(cv[2]))\nax[1].set_title(title, fontsize=12)\n\nax[2].imshow(cv[1], cmap=\"gray\")\nax[2].set_axis_off()\nax[2].set_title(\"Final Level Set\", fontsize=12)\n\nax[3].plot(cv[2])\nax[3].set_title(\"Evolution of energy over iterations\", fontsize=12)\n\nfig.tight_layout()\nfig.savefig('chan_vese.png', dpi = 300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:14:30.616927Z","iopub.execute_input":"2023-04-15T18:14:30.617282Z","iopub.status.idle":"2023-04-15T18:14:32.394238Z","shell.execute_reply.started":"2023-04-15T18:14:30.617255Z","shell.execute_reply":"2023-04-15T18:14:32.392882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing(image): # to create the black and white contrast mask used to calculate ABD values\n    image = dullrazor(image, showimgs=False)\n    image = cv2.fastNlMeansDenoisingColored(image,None,2,2,7,21)\n    image_gray = skimage.color.rgb2gray(image)\n    t = skimage.filters.threshold_otsu(image_gray)\n    binary_mask = image_gray < t\n    selection = image.copy()\n    selection[~binary_mask] = 0\n    image = skimage.color.rgb2gray(selection)\n    cv = chan_vese(image, mu=0.5, lambda1=1, lambda2=1, tol=1e-3, max_num_iter=100,\n               dt=0.5, init_level_set=\"checkerboard\", extended_output=True)\n    y = 1*cv[0]\n    return y","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:30:04.880641Z","iopub.execute_input":"2023-04-15T20:30:04.880986Z","iopub.status.idle":"2023-04-15T20:30:04.888703Z","shell.execute_reply.started":"2023-04-15T20:30:04.88094Z","shell.execute_reply":"2023-04-15T20:30:04.887436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def partial_preprocessing(image): # to overlay the black mask on the image to get the color varegation value\n    image = dullrazor(image, showimgs=False)\n    image = cv2.fastNlMeansDenoisingColored(image,None,2,2,7,21)\n    image_gray = skimage.color.rgb2gray(image)\n    t = skimage.filters.threshold_otsu(image_gray)\n    binary_mask = image_gray < t\n    selection = image.copy()\n    selection[~binary_mask] = 0\n\n    return selection","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:16:07.343405Z","iopub.execute_input":"2023-04-15T18:16:07.34381Z","iopub.status.idle":"2023-04-15T18:16:07.351218Z","shell.execute_reply.started":"2023-04-15T18:16:07.343776Z","shell.execute_reply":"2023-04-15T18:16:07.349739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_test = read(os.path.join(\"/kaggle/input/skin-cancer-malignant-vs-benign/test/malignant/\", \"1012.jpg\"))\nimg_test_array = np.array(img_test, dtype='uint8')\nplt.imshow(preprocessing(img_test_array), cmap=\"gray\")\nplt.savefig('finalcontour.png', dpi = 300)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T20:30:34.276013Z","iopub.execute_input":"2023-04-15T20:30:34.276388Z","iopub.status.idle":"2023-04-15T20:30:35.529695Z","shell.execute_reply.started":"2023-04-15T20:30:34.276357Z","shell.execute_reply":"2023-04-15T20:30:35.528839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_img = label(preprocessing(img_test_array), connectivity=preprocessing(img_test_array).ndim)\nprops = regionprops(label_img)\ncentroid = props[0].centroid\n#print(centroid)\n\nfig=plt.figure(figsize=(24, 16))\ncolumns = 5\nrows = 1\n\n# segmented image with centroid\nfig.add_subplot(rows, columns, 1)\nplt.plot(centroid[0],centroid[1], marker='.', color=\"blue\")\nplt.imshow(preprocessing(img_test_array),cmap = \"gray\")\n\n\n# rotation about centroid by orientation angle\nangle = props[0].orientation * (180/math.pi)\nM = cv2.getRotationMatrix2D((centroid[0],centroid[1]), angle, 1.0)\nrotated_image = cv2.warpAffine(preprocessing(img_test_array).astype(np.uint8), M, (224, 224))\nfig.add_subplot(rows, columns, 2)\nplt.plot(centroid[0],centroid[1], marker='.', color=\"blue\")\nplt.imshow(rotated_image,cmap = \"gray\")\n\n\n# transpose to centre\nhh, ww = rotated_image.shape\n# get contours (presumably just one around the nonzero pixels) \ncontours = cv2.findContours(rotated_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncontours = contours[0] if len(contours) == 2 else contours[1]\nfor cntr in contours:\n    x,y,w,h = cv2.boundingRect(cntr)\n    \n# recenter\nstartx = (ww - w)//2\nstarty = (hh - h)//2\nresult = np.zeros_like(rotated_image)\nresult[starty:starty+h,startx:startx+w] = rotated_image[y:y+h,x:x+w]\n# view result\nfig.add_subplot(rows, columns, 3)\nplt.plot(112,112, marker='.', color=\"blue\")\nplt.imshow(result,cmap = \"gray\")\n\n\n#flipped horixontally along x-axis\nflipped_x = cv2.flip(result, 0) # 0 for x-axis\nfig.add_subplot(rows, columns, 4)\nplt.plot(112,112, marker='.', color=\"blue\")\nplt.imshow(flipped_x,cmap = \"gray\")\n\n\n#flipped horixontally along y-axis\nflipped_y = cv2.flip(result, 1) # 1 for y-axis\nfig.add_subplot(rows, columns, 5)\nplt.plot(112,112, marker='.', color=\"blue\")\nplt.imshow(flipped_y,cmap = \"gray\")","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:16:14.64719Z","iopub.execute_input":"2023-04-15T18:16:14.647588Z","iopub.status.idle":"2023-04-15T18:16:17.541061Z","shell.execute_reply.started":"2023-04-15T18:16:14.647555Z","shell.execute_reply":"2023-04-15T18:16:17.539718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ABCD rule\nfig=plt.figure(figsize=(12,8))\ncolumns = 2\nrows = 1\n\n# XOR with Numpy\ndLx = np.bitwise_xor(result,flipped_x).astype(np.uint8)\ndLy = np.bitwise_xor(result,flipped_y).astype(np.uint8)\n\nfig.add_subplot(rows, columns, 1)\nplt.imshow(dLx,cmap = \"gray\")\nplt.savefig('dLx.png', dpi = 300)\n\nfig.add_subplot(rows, columns, 2)\nplt.imshow(dLy,cmap = \"gray\")\nplt.savefig('dLy.png', dpi = 300)\n\n\n# Color variegation:\nim = Image.fromarray(selection.astype('uint8'), 'RGB')\nstat = ImageStat.Stat(im)\nC_r = stat.stddev[0] / stat.extrema[0][1]\nC_g = stat.stddev[1] / stat.extrema[1][1]\nC_b = stat.stddev[2] / stat.extrema[2][1]\n\n# Texture: Gray Level Co-occurrence Matrix (GLCM)\ngray_img = cv2.cvtColor(img_test_array, cv2.COLOR_BGR2GRAY)\nglcm = feature.graycomatrix(image=img_as_ubyte(gray_img), distances=[1],angles=[0, np.pi/4, np.pi/2, np.pi * 3/2],symmetric=True, normed=True)\ncorrelation = np.mean(feature.graycoprops(glcm, prop='correlation'))\nhomogeneity = np.mean(feature.graycoprops(glcm, prop='homogeneity'))\nenergy = np.mean(feature.graycoprops(glcm, prop='energy'))\ncontrast = np.mean(feature.graycoprops(glcm, prop='contrast'))\n\n\n# property calculations\nr = regionprops(result)[0]\na1 = regionprops(dLx)[0].area/r.area # Asymmetry score across x-axis\na2 = regionprops(dLy)[0].area/r.area # Asymmetry score across y-axis\nAI = (a1+a2)/2 # Asymmetricity Index\n\nb1 = r.area/r.perimeter # Area to perimeter ratio\nb2 = (4*math.pi*r.area)/(r.perimeter*r.perimeter) # Compactness index\nb3 = r.perimeter*r.area # Perimeter multiplied by area\n\nD1 = math.sqrt((4*r.area)/math.pi)\nD2 = (r.axis_major_length+r.axis_minor_length)/2\nd1 = ((D1+D2)/2)*0.265 # Average diameter of the lesion (1px = 0.265mm)\nd2 = r.axis_major_length-r.axis_minor_length # Difference between principal axes lengths\n\n\n# print property values\nprint(\"Perimeter {:.3f}: \".format(r.perimeter))\nprint(\"Area {:.3f}:\".format(r.area))\nprint(\"A1 (Asymmetry score across x-axis) {:.3f}: \".format(a1))\nprint(\"A2 (Asymmetry score across y-axis) {:.3f}: \".format(a2))\nprint(\"AI (Asymmetricity Index) {:.3f}: \".format(AI))\n\nprint(\"B1 (Area to perimeter ratio) {:.3f}: \".format(b1))\nprint(\"B2 (Compactness index) {:.3f}:\".format(b2))\nprint(\"B3 (Perimeter multiplied by area) {:.3f}:\".format(b3))\n\nprint(\"D1 (Average diameter of the lesion) {:.3f}:\".format(d1))\nprint(\"D2 (Difference between principal axes lengths) {:.3f}:\".format(d2))\n\nprint('Red Std Deviation: {:.3f}'.format(C_r))\nprint('Green Std Deviation: {:.3f}'.format(C_g))\nprint('Blue Std Deviation: {:.3f}'.format(C_b))\n\nprint('Correlation: {:.3f}'.format(correlation))\nprint('Homogeneity: {:.3f}'.format(homogeneity))\nprint('Energy: {:.3f}'.format(energy))\nprint('Contrast: {:.3f}'.format(contrast))","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:16:21.45185Z","iopub.execute_input":"2023-04-15T18:16:21.45225Z","iopub.status.idle":"2023-04-15T18:16:23.169396Z","shell.execute_reply.started":"2023-04-15T18:16:21.452219Z","shell.execute_reply":"2023-04-15T18:16:23.168375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of distict color classes whose presence in the image>5%\n\nPIL_image = Image.fromarray(selection.astype('uint8'), 'RGB')\ncolors_x = extcolors.extract_from_image(PIL_image, tolerance = 4, limit = 50)\n\ndef hextriplet(colortuple):\n    return '#' + ''.join(f'{i:02X}' for i in colortuple)\n\ndef color_to_df(input):\n    colors_pre_list = str(input).replace('([(','').split(', (')[0:-1]\n    df_rgb = [i.split('), ')[0] + ')' for i in colors_pre_list]\n    df_percent = [i.split('), ')[1].replace(')','') for i in colors_pre_list]\n    #print(type(df_rgb[0]))\n    #convert RGB to HEX code\n    \n    df_color_up = [hextriplet(tuple(map(int, ((test_str.replace('(','')).replace(')','')).split(', ')))) for test_str in df_rgb]\n    \n    df = pd.DataFrame(zip(df_color_up,df_rgb,df_percent), columns = ['c_code','rgb','occurence'])\n    return df\n\ndf_color = color_to_df(colors_x)\n\nlist_color = list(df_color['c_code'])\nlist_occurrence = [int(i) for i in list(df_color['occurence'])]\nlist_rgb = [tuple(map(int, ((test_str.replace('(','')).replace(')','')).split(', '))) for test_str in list(df_color['rgb'])] \nlist_percent = [round((p*100)/sum(list_occurrence),3) for p in list_occurrence]\n\ncolor = [0]*6\nfor i in range(0,len(list_rgb)):\n    r = list_rgb[i][0]\n    g = list_rgb[i][1]\n    b = list_rgb[i][2]\n    p = list_percent[i]\n    \n    if r>=(0.8*255) and g>=(0.8*255) and b>=(0.8*255):\n        color[0]+=p #white\n    elif r>=(0.588*255) and g<(0.2*255) and b<(0.2*255):\n        color[1]+=p #red\n    elif (r>=(0.588*255) and r<=(0.94*255)) and (g>(0.2*255) and g<=(0.588*255)) and (b>0 and b<(0.392*255)):\n        color[2]+=p #lightbrown\n    elif (r>(0.243*255) and r<(0.56*255)) and g<(0.392*255) and (b>0 and b<(0.392*255)):\n        color[3]+=p #darkbrown\n    elif r<=(0.588*255) and (g>=(0.392*255) and g<=(0.588*255)) and (b>=(0.490*255) and b<=(0.588*255)):\n        color[4]+=p #bluegray\n    elif r<=(0.243*255) and g<=(0.243*255) and b<=(0.243*255):\n        color[5]+=p #black\n    \n# using list comprehension\n# to get numbers > 5%\ncount = len([i for i in color if i > 5])    \nprint(\"Number of distinct color classes :\", count)","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:16:56.51435Z","iopub.execute_input":"2023-04-15T18:16:56.51474Z","iopub.status.idle":"2023-04-15T18:16:56.629045Z","shell.execute_reply.started":"2023-04-15T18:16:56.514712Z","shell.execute_reply":"2023-04-15T18:16:56.627219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total dermoscopic score ≥ 5.45 is highly suggestive of melanoma\n#Total dermoscopic score = 1.3 (A score) + 0.1 (B score) + 0.5 (C score) + 0.5 (D score)\nTDS_old1 = (1.3*AI)+(0.1*b2)+(0.5*count)+(0.5*d1)\nTDS_old2 = (1.3*AI)+(0.1*(1/b2))+(0.5*count)+(0.5*d1)\nprint(TDS_old1)\nprint(TDS_old2)\n\n#New TDS = (1.3*AsymmetryIndex)+(0.1*BorderIrregularity)\n#+(0.5*Black)+(0.5*White)+(0.5*Red)+(0.5*Blue)+(0.3*DarkBrown)+(0.4*LightBrown)+(0.5*Diameter)\nTDS_new1 = (1.3*AI)+(0.1*b2)+(0.5*color[0])+(0.5*color[1])+(0.4*color[2])+(0.3*color[3])+(0.5*color[4])+(0.5*color[5])+(0.5*d1)\nTDS_new2 = (1.3*AI)+(0.1*(1/b2))+(0.5*color[0])+(0.5*color[1])+(0.4*color[2])+(0.3*color[3])+(0.5*color[4])+(0.5*color[5])+(0.5*d1)\nprint(TDS_new1)\nprint(TDS_new2)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:17:00.674732Z","iopub.execute_input":"2023-04-15T18:17:00.67512Z","iopub.status.idle":"2023-04-15T18:17:00.685653Z","shell.execute_reply.started":"2023-04-15T18:17:00.675088Z","shell.execute_reply":"2023-04-15T18:17:00.684097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feature extration (attempt 2)\n\nlesion_region = regionprops(preprocessing(img_test_array))[0]\narea_total = lesion_region.area\nimg_mask = lesion_region.image\n\nhorizontal_flip = np.fliplr(img_mask)\ndiff_horizontal = img_mask * ~horizontal_flip\n\nvertical_flip = np.flipud(img_mask)\ndiff_vertical = img_mask * ~vertical_flip\ndiff_horizontal_area = np.count_nonzero(diff_horizontal)\ndiff_vertical_area = np.count_nonzero(diff_vertical)\na1 = diff_horizontal_area / area_total\na2 = diff_vertical_area / area_total\nasymm_idx = 0.5 * (a1 + a2)\necc = lesion_region.eccentricity\n\nprint('Primeter: {:.3f}'.format(lesion_region.perimeter))\nprint('Area: {:.3f}'.format(lesion_region.area))\n\nprint('-- ASYMMETRY --')\nprint('Diff area horizontal: {:.3f}'.format(np.count_nonzero(diff_horizontal)))\nprint('Diff area vertical: {:.3f}'.format(np.count_nonzero(diff_vertical)))\nprint(\"A1 (Asymmetry score across x-axis) {:.3f}: \".format(a1))\nprint(\"A2 (Asymmetry score across y-axis) {:.3f}: \".format(a2))\nprint('Asymmetric Index: {:.3f}'.format(asymm_idx))\nprint('Eccentricity: {:.3f}'.format(ecc))\n# print('Minor-Major axis ratio: {}'.format(mmr))\n        \nimshow_all(img_mask, horizontal_flip, diff_horizontal,titles=['image mask', 'horizontal flip', 'difference'], size=4, cmap='gray')\nplt.savefig('transforms1.png', dpi = 300)\nimshow_all(img_mask, vertical_flip, diff_vertical,titles=['image mask', 'vertical flip', 'difference'], size=4, cmap='gray')\nplt.savefig('transforms2.png', dpi = 300)\nplt.show();\n\n# Border Irregularity: Compactness index\ncompact_index = (4 * np.pi * area_total)/(lesion_region.perimeter ** 2) #formula confusion(cleck later)\nb1 =  lesion_region.area/lesion_region.perimeter # area to perimeter ratio\nprint('\\n-- BORDER IRREGULARITY --')\n\nprint('Compact Index: {:.3f}'.format(compact_index))\n\n# Diameter\neq_diameter = lesion_region.equivalent_diameter\nD1 = math.sqrt((4*lesion_region.area)/math.pi)\nD2 = (lesion_region.axis_major_length+lesion_region.axis_minor_length)/2\nd1 = ((D1+D2)/2)*0.265 # Average diameter of the lesion (1px = 0.265mm)\nd2 = lesion_region.axis_major_length-lesion_region.axis_minor_length # Difference between principal axes lengths\nprint('\\n-- DIAMETER --')\n#print('Equivalent diameter: {:.3f}'.format(eq_diameter))\n# optionally convert the diameter in mm, knowing that 1 px = 0.265 mm:\n# 1 px : 0.265 mm = diam_px : diam_mm -> diam_mm = diam_px * 0.265\nprint('Diameter (mm): {:.3f}'.format(eq_diameter * 0.265))\nprint(\"D1 (Average diameter of the lesion) {:.3f}:\".format(d1))\nprint(\"D2 (Difference between principal axes lengths) {:.3f}:\".format(d2))\n\n# Color variegation:\nim = Image.fromarray(selection.astype('uint8'), 'RGB')\nstat = ImageStat.Stat(im)\nC_r = stat.stddev[0] / stat.extrema[0][1]\nC_g = stat.stddev[1] / stat.extrema[1][1]\nC_b = stat.stddev[2] / stat.extrema[2][1]\nprint('\\n-- COLOR VARIEGATION --')\nprint('Red Std Deviation: {:.3f}'.format(C_r))\nprint('Green Std Deviation: {:.3f}'.format(C_g))\nprint('Blue Std Deviation: {:.3f}'.format(C_b))\n\n# Texture: Gray Level Co-occurrence Matrix (GLCM)\ngray_image = cv2.cvtColor(img_test_array, cv2.COLOR_BGR2GRAY)\nglcm = feature.graycomatrix(image=img_as_ubyte(gray_img), distances=[1],angles=[0, np.pi/4, np.pi/2, np.pi * 3/2],symmetric=True, normed=True)\ncorrelation = np.mean(feature.graycoprops(glcm, prop='correlation'))\nhomogeneity = np.mean(feature.graycoprops(glcm, prop='homogeneity'))\nenergy = np.mean(feature.graycoprops(glcm, prop='energy'))\ncontrast = np.mean(feature.graycoprops(glcm, prop='contrast'))\nprint('\\n-- TEXTURE --')\nprint('Correlation: {:.3f}'.format(correlation))\nprint('Homogeneity: {:.3f}'.format(homogeneity))\nprint('Energy: {:.3f}'.format(energy))\nprint('Contrast: {:.3f}'.format(contrast))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:20:45.967031Z","iopub.execute_input":"2023-04-15T18:20:45.967499Z","iopub.status.idle":"2023-04-15T18:20:49.018507Z","shell.execute_reply.started":"2023-04-15T18:20:45.967464Z","shell.execute_reply":"2023-04-15T18:20:49.017045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using feature selection process 2\ndef feature_extraction(img_test_array):\n    properties = list()\n    lesion_region = regionprops(preprocessing(img_test_array))[0]\n    selection = partial_preprocessing(img_test_array)\n    \n    area_total = lesion_region.area\n    img_mask = lesion_region.image\n    horizontal_flip = np.fliplr(img_mask)\n    diff_horizontal = img_mask * ~horizontal_flip\n    \n    vertical_flip = np.flipud(img_mask)\n    diff_vertical = img_mask * ~vertical_flip\n    \n    diff_horizontal_area = np.count_nonzero(diff_horizontal)\n    diff_vertical_area = np.count_nonzero(diff_vertical)\n    a1 = diff_horizontal_area / area_total # Asymmetry score across x-axis\n    a2 = diff_vertical_area / area_total # Asymmetry score across y-axis\n    asymm_idx = 0.5 * (a1 + a2) # Asymmetricity Index\n    ecc = lesion_region.eccentricity\n    \n    # Border Irregularity: Compactness index\n    compactness_index = (4 * math.pi * area_total)/(lesion_region.perimeter*lesion_region.perimeter) #formula confusion(cleck later)\n    b1 =  lesion_region.area/lesion_region.perimeter # area to perimeter ratio\n    \n    # Diameter\n    eq_diameter = lesion_region.equivalent_diameter\n    D1 = math.sqrt((4*lesion_region.area)/math.pi)\n    D2 = (lesion_region.axis_major_length+lesion_region.axis_minor_length)/2\n    d1 = ((D1+D2)/2)*0.265 # Average diameter of the lesion (1px = 0.265mm)\n    d2 = lesion_region.axis_major_length-lesion_region.axis_minor_length # Difference between principal axes lengths\n    \n    # Color variegation:\n    im = Image.fromarray(selection.astype('uint8'), 'RGB')\n    stat = ImageStat.Stat(im)\n    C_r = stat.stddev[0] / stat.extrema[0][1]\n    C_g = stat.stddev[1] / stat.extrema[1][1]\n    C_b = stat.stddev[2] / stat.extrema[2][1]\n\n    # Texture: Gray Level Co-occurrence Matrix (GLCM)\n    gray_img = cv2.cvtColor(img_test_array, cv2.COLOR_BGR2GRAY)\n    glcm = feature.graycomatrix(image=img_as_ubyte(gray_img), distances=[1],angles=[0, np.pi/4, np.pi/2, np.pi * 3/2],symmetric=True, normed=True)\n    correlation = np.mean(feature.graycoprops(glcm, prop='correlation'))\n    homogeneity = np.mean(feature.graycoprops(glcm, prop='homogeneity'))\n    energy = np.mean(feature.graycoprops(glcm, prop='energy'))\n    contrast = np.mean(feature.graycoprops(glcm, prop='contrast'))\n\n    properties.append(lesion_region.area)\n    properties.append(lesion_region.perimeter)\n    properties.append(diff_horizontal_area)\n    properties.append(diff_vertical_area)\n    properties.append(a1)\n    properties.append(a2)\n    properties.append(asymm_idx)\n    properties.append(ecc)\n    \n    properties.append(compact_index)\n    properties.append(b1)\n\n    properties.append(d1)\n    properties.append(d2)\n    properties.append(eq_diameter * 0.265)\n    \n    properties.append(C_r)\n    properties.append(C_g)\n    properties.append(C_b)\n    \n    properties.append(correlation)\n    properties.append(homogeneity)\n    properties.append(energy)\n    properties.append(contrast)\n    \n    colors_x = extcolors.extract_from_image(im, tolerance = 4, limit = 50)\n    \n    def hextriplet(colortuple):\n        return '#' + ''.join(f'{i:02X}' for i in colortuple)\n\n    def color_to_df(input):\n        colors_pre_list = str(input).replace('([(','').split(', (')[0:-1]\n        df_rgb = [i.split('), ')[0] + ')' for i in colors_pre_list]\n        df_percent = [i.split('), ')[1].replace(')','') for i in colors_pre_list]\n        #print(type(df_rgb[0]))\n        #convert RGB to HEX code\n    \n        df_color_up = [hextriplet(tuple(map(int, ((test_str.replace('(','')).replace(')','')).split(', ')))) for test_str in df_rgb]\n    \n        df = pd.DataFrame(zip(df_color_up,df_rgb,df_percent), columns = ['c_code','rgb','occurence'])\n        return df\n\n    df_color = color_to_df(colors_x)\n\n    list_color = list(df_color['c_code'])\n    list_occurrence = [int(i) for i in list(df_color['occurence'])]\n    list_rgb = [tuple(map(int, ((test_str.replace('(','')).replace(')','')).split(', '))) for test_str in list(df_color['rgb'])] \n    list_percent = [round((p*100)/sum(list_occurrence),3) for p in list_occurrence]\n\n    color = [0]*6\n    for i in range(0,len(list_rgb)):\n        r = list_rgb[i][0]\n        g = list_rgb[i][1]\n        b = list_rgb[i][2]\n        p = list_percent[i]\n    \n        if r>=(0.8*255) and g>=(0.8*255) and b>=(0.8*255):\n            color[0]+=p #white\n        elif r>=(0.588*255) and g<(0.2*255) and b<(0.2*255):\n            color[1]+=p #red\n        elif (r>=(0.588*255) and r<=(0.94*255)) and (g>(0.2*255) and g<=(0.588*255)) and (b>0 and b<(0.392*255)):\n            color[2]+=p #lightbrown\n        elif (r>(0.243*255) and r<(0.56*255)) and g<(0.392*255) and (b>0 and b<(0.392*255)):\n            color[3]+=p #darkbrown\n        elif r<=(0.588*255) and (g>=(0.392*255) and g<=(0.588*255)) and (b>=(0.490*255) and b<=(0.588*255)):\n            color[4]+=p #bluegray\n        elif r<=(0.243*255) and g<=(0.243*255) and b<=(0.243*255):\n            color[5]+=p #black\n    \n    # using list comprehension\n    # to get numbers > 5%\n    color_count = len([i for i in color if i > 5])    \n    properties.append(color_count)\n    \n    #properties list:\n    #[area, perimeter, dLx, dLy, a1, a2, AI, eccentricity, compactness_index, b1, d1, d2, equivalent_diameter, C_r, C_g, C_b, correlation, homogeneity, energy, contrast, color_count]\n\n    return properties","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:00:11.015617Z","iopub.execute_input":"2023-03-31T19:00:11.015916Z","iopub.status.idle":"2023-03-31T19:00:11.042198Z","shell.execute_reply.started":"2023-03-31T19:00:11.015889Z","shell.execute_reply":"2023-03-31T19:00:11.041161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(img_test_array))\nprint(len(feature_extraction(img_test_array)))\nprint(feature_extraction(img_test_array))","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:00:11.043461Z","iopub.execute_input":"2023-03-31T19:00:11.044233Z","iopub.status.idle":"2023-03-31T19:00:13.349779Z","shell.execute_reply.started":"2023-03-31T19:00:11.044196Z","shell.execute_reply":"2023-03-31T19:00:13.348731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.DataFrame(columns = ['area', 'perimeter', 'dLx', 'dLy', 'a1', 'a2', 'AI', 'eccentricity', 'compactness_index', 'b1', 'd1', 'd2', 'equivalent_diameter', 'C_r', 'C_g', 'C_b', 'correlation', 'homogeneity', 'energy', 'contrast', 'color_count'])\ndf_test = pd.DataFrame(columns = ['area', 'perimeter', 'dLx', 'dLy', 'a1', 'a2', 'AI', 'eccentricity', 'compactness_index', 'b1', 'd1', 'd2', 'equivalent_diameter', 'C_r', 'C_g', 'C_b', 'correlation', 'homogeneity', 'energy', 'contrast', 'color_count'])","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:00:13.351357Z","iopub.execute_input":"2023-03-31T19:00:13.351988Z","iopub.status.idle":"2023-03-31T19:00:13.362635Z","shell.execute_reply.started":"2023-03-31T19:00:13.351932Z","shell.execute_reply":"2023-03-31T19:00:13.361575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(X_train[0]))\nprint(type(img_test_array))\nprint(X_train[0].shape)\nprint(img_test_array.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:00:13.364922Z","iopub.execute_input":"2023-03-31T19:00:13.366212Z","iopub.status.idle":"2023-03-31T19:00:13.373921Z","shell.execute_reply.started":"2023-03-31T19:00:13.366183Z","shell.execute_reply":"2023-03-31T19:00:13.372863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = feature_extraction(X_test[5])\nprint(p)\nprint(len(p))\nprint(type(p))","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:00:13.37552Z","iopub.execute_input":"2023-03-31T19:00:13.375998Z","iopub.status.idle":"2023-03-31T19:00:14.351366Z","shell.execute_reply.started":"2023-03-31T19:00:13.375941Z","shell.execute_reply":"2023-03-31T19:00:14.350318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntdata = list()\nfor i in range(X_train.shape[0]):\n    p = feature_extraction(X_train[i])\n    tdata.append(p)\n    print(i, end = \" \")\ndf_train = pd.DataFrame(tdata, columns = ['area', 'perimeter', 'dLx', 'dLy', 'a1', 'a2', 'AI', 'eccentricity', 'compactness_index', 'b1', 'd1', 'd2', 'equivalent_diameter', 'C_r', 'C_g', 'C_b', 'correlation', 'homogeneity', 'energy', 'contrast', 'color_count'])\n'''","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:00:14.352968Z","iopub.execute_input":"2023-03-31T19:00:14.353337Z","iopub.status.idle":"2023-03-31T19:00:14.361144Z","shell.execute_reply.started":"2023-03-31T19:00:14.353302Z","shell.execute_reply":"2023-03-31T19:00:14.36Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:00:14.362768Z","iopub.execute_input":"2023-03-31T19:00:14.363624Z","iopub.status.idle":"2023-03-31T19:00:14.369202Z","shell.execute_reply.started":"2023-03-31T19:00:14.36359Z","shell.execute_reply":"2023-03-31T19:00:14.368254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add classes\n#df_train['dianosis'] = y_train","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:00:14.3705Z","iopub.execute_input":"2023-03-31T19:00:14.37092Z","iopub.status.idle":"2023-03-31T19:00:14.378868Z","shell.execute_reply.started":"2023-03-31T19:00:14.370884Z","shell.execute_reply":"2023-03-31T19:00:14.377822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:00:14.380394Z","iopub.execute_input":"2023-03-31T19:00:14.380811Z","iopub.status.idle":"2023-03-31T19:00:14.38968Z","shell.execute_reply.started":"2023-03-31T19:00:14.380778Z","shell.execute_reply":"2023-03-31T19:00:14.388775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_train.to_csv('df_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:00:14.390934Z","iopub.execute_input":"2023-03-31T19:00:14.391304Z","iopub.status.idle":"2023-03-31T19:00:14.399281Z","shell.execute_reply.started":"2023-03-31T19:00:14.391271Z","shell.execute_reply":"2023-03-31T19:00:14.398306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdata = list()\nfor i in range(X_test.shape[0]):\n    p = feature_extraction(X_test[i])\n    tdata.append(p)\n    print(i, end = \" \")\ndf_test = pd.DataFrame(tdata, columns = ['area', 'perimeter', 'dLx', 'dLy', 'a1', 'a2', 'AI', 'eccentricity', 'compactness_index', 'b1', 'd1', 'd2', 'equivalent_diameter', 'C_r', 'C_g', 'C_b', 'correlation', 'homogeneity', 'energy', 'contrast', 'color_count'])","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:00:14.400932Z","iopub.execute_input":"2023-03-31T19:00:14.401296Z","iopub.status.idle":"2023-03-31T19:11:20.8336Z","shell.execute_reply.started":"2023-03-31T19:00:14.401265Z","shell.execute_reply":"2023-03-31T19:11:20.832623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:11:20.835009Z","iopub.execute_input":"2023-03-31T19:11:20.835471Z","iopub.status.idle":"2023-03-31T19:11:20.865682Z","shell.execute_reply.started":"2023-03-31T19:11:20.835434Z","shell.execute_reply":"2023-03-31T19:11:20.864485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add classes\ndf_test['dianosis'] = y_test","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:11:20.867381Z","iopub.execute_input":"2023-03-31T19:11:20.867739Z","iopub.status.idle":"2023-03-31T19:11:20.872507Z","shell.execute_reply.started":"2023-03-31T19:11:20.867704Z","shell.execute_reply":"2023-03-31T19:11:20.871553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:11:20.873921Z","iopub.execute_input":"2023-03-31T19:11:20.874548Z","iopub.status.idle":"2023-03-31T19:11:20.900875Z","shell.execute_reply.started":"2023-03-31T19:11:20.874514Z","shell.execute_reply":"2023-03-31T19:11:20.9Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.to_csv('df_test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:11:20.902388Z","iopub.execute_input":"2023-03-31T19:11:20.902885Z","iopub.status.idle":"2023-03-31T19:11:20.926464Z","shell.execute_reply.started":"2023-03-31T19:11:20.902756Z","shell.execute_reply":"2023-03-31T19:11:20.92542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display first 15 images of moles, and how they are classified\nw=40\nh=30\nfig=plt.figure(figsize=(12, 8))\ncolumns = 5\nrows = 3\n\nfor i in range(1, columns*rows +1):\n    ax = fig.add_subplot(rows, columns, i)\n    if y_train[i] == 0:\n        ax.title.set_text('Benign')\n    else:\n        ax.title.set_text('Malignant')\n    plt.imshow(X_train[i], interpolation='nearest')\nplt.savefig('image_classes.png', dpi = 300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:18:17.021843Z","iopub.execute_input":"2023-04-15T18:18:17.022211Z","iopub.status.idle":"2023-04-15T18:18:19.7805Z","shell.execute_reply.started":"2023-04-15T18:18:17.022175Z","shell.execute_reply":"2023-04-15T18:18:19.779745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display first 15 images of moles, and how they are classified (POST Pre-Processing)\nw=40\nh=30\nfig=plt.figure(figsize=(12, 8))\ncolumns = 5\nrows = 3\n\nfor i in range(1, columns*rows +1):\n    ax = fig.add_subplot(rows, columns, i)\n    if y_train[i] == 0:\n        ax.title.set_text('Benign')\n    else:\n        ax.title.set_text('Malignant')\n    plt.imshow(preprocessing(X_train[i]), cmap=\"gray\")\nplt.savefig('preprocessed_image_classes.png', dpi = 300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-15T18:21:52.264064Z","iopub.execute_input":"2023-04-15T18:21:52.264423Z","iopub.status.idle":"2023-04-15T18:22:02.562358Z","shell.execute_reply.started":"2023-04-15T18:21:52.264393Z","shell.execute_reply":"2023-04-15T18:22:02.561479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n#print(X_train.shape[0])\nt = list()\nfor i in range(X_train.shape[0]):\n    t.append(partial_preprocessing(X_train[i]))\n    print(i, end = \" \")\nX_train = t\n'''","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:11:34.878874Z","iopub.execute_input":"2023-03-31T19:11:34.881502Z","iopub.status.idle":"2023-03-31T19:11:34.892394Z","shell.execute_reply.started":"2023-03-31T19:11:34.881456Z","shell.execute_reply":"2023-03-31T19:11:34.890871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X_train = np.array(X_train)\n#print(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:11:34.895881Z","iopub.execute_input":"2023-03-31T19:11:34.897498Z","iopub.status.idle":"2023-03-31T19:11:34.904537Z","shell.execute_reply.started":"2023-03-31T19:11:34.89746Z","shell.execute_reply":"2023-03-31T19:11:34.903562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#np.save(\"x_train\", X_train)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:11:34.906013Z","iopub.execute_input":"2023-03-31T19:11:34.907786Z","iopub.status.idle":"2023-03-31T19:11:34.917414Z","shell.execute_reply.started":"2023-03-31T19:11:34.907746Z","shell.execute_reply":"2023-03-31T19:11:34.916155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(X_test.shape[0])\nt = list()\nfor i in range(X_test.shape[0]):\n    t.append(partial_preprocessing(X_test[i]))\n    print(i, end = \" \")\nX_test = t","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:11:34.918776Z","iopub.execute_input":"2023-03-31T19:11:34.919929Z","iopub.status.idle":"2023-03-31T19:13:20.733241Z","shell.execute_reply.started":"2023-03-31T19:11:34.919891Z","shell.execute_reply":"2023-03-31T19:13:20.732183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.array(X_test)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:13:20.734966Z","iopub.execute_input":"2023-03-31T19:13:20.735669Z","iopub.status.idle":"2023-03-31T19:13:20.771993Z","shell.execute_reply.started":"2023-03-31T19:13:20.735627Z","shell.execute_reply":"2023-03-31T19:13:20.770834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save(\"x_test\", X_test)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:13:20.773615Z","iopub.execute_input":"2023-03-31T19:13:20.77401Z","iopub.status.idle":"2023-03-31T19:13:20.849803Z","shell.execute_reply.started":"2023-03-31T19:13:20.773973Z","shell.execute_reply":"2023-03-31T19:13:20.848817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#np.save(\"y_train\", y_train)\nnp.save(\"y_test\", y_test)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:13:20.851452Z","iopub.execute_input":"2023-03-31T19:13:20.851839Z","iopub.status.idle":"2023-03-31T19:13:20.857629Z","shell.execute_reply.started":"2023-03-31T19:13:20.851803Z","shell.execute_reply":"2023-03-31T19:13:20.855935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = np.load('/kaggle/input/skincancer-keras-cnn/iisic_train_test_segmented_image_array/y_train.npy')\ny_test = np.load('/kaggle/input/skincancer-keras-cnn/iisic_train_test_segmented_image_array/y_test.npy')\nX_train = np.load('/kaggle/input/skincancer-keras-cnn/iisic_train_test_segmented_image_array/x_train.npyy')\nX_test = np.load('/kaggle/input/skincancer-keras-cnn/iisic_train_test_segmented_image_array/x_test.npy')","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:13:20.859806Z","iopub.execute_input":"2023-03-31T19:13:20.860749Z","iopub.status.idle":"2023-03-31T19:13:21.053185Z","shell.execute_reply.started":"2023-03-31T19:13:20.860714Z","shell.execute_reply":"2023-03-31T19:13:21.052194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:13:21.054739Z","iopub.execute_input":"2023-03-31T19:13:21.055128Z","iopub.status.idle":"2023-03-31T19:13:21.274971Z","shell.execute_reply.started":"2023-03-31T19:13:21.05509Z","shell.execute_reply":"2023-03-31T19:13:21.274016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 4 : Normalization:** Normalize all Values of the pictures by dividing all the RGB values by 255","metadata":{}},{"cell_type":"code","source":"# With data augmentation to prevent overfitting \nX_train = X_train/255.\nX_test = X_test/255.","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:13:21.276302Z","iopub.execute_input":"2023-03-31T19:13:21.277453Z","iopub.status.idle":"2023-03-31T19:13:22.511134Z","shell.execute_reply.started":"2023-03-31T19:13:21.277411Z","shell.execute_reply":"2023-03-31T19:13:22.510017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:13:22.512504Z","iopub.execute_input":"2023-03-31T19:13:22.513104Z","iopub.status.idle":"2023-03-31T19:13:22.520444Z","shell.execute_reply.started":"2023-03-31T19:13:22.513067Z","shell.execute_reply":"2023-03-31T19:13:22.519124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting training into Train and Validatation sets\nX_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size = 0.2,random_state=123)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:13:22.522475Z","iopub.execute_input":"2023-03-31T19:13:22.523524Z","iopub.status.idle":"2023-03-31T19:13:23.514Z","shell.execute_reply.started":"2023-03-31T19:13:22.523481Z","shell.execute_reply":"2023-03-31T19:13:23.512992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T19:13:23.518456Z","iopub.execute_input":"2023-03-31T19:13:23.519289Z","iopub.status.idle":"2023-03-31T19:13:23.530238Z","shell.execute_reply.started":"2023-03-31T19:13:23.519252Z","shell.execute_reply":"2023-03-31T19:13:23.528999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Feature Training**","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/skincancer-keras-cnn/SkinCancer Features/df_test.csv')\ndf_train = pd.read_csv('/kaggle/input/skincancer-keras-cnn/SkinCancer Features/df_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:22:44.943691Z","iopub.execute_input":"2023-04-10T20:22:44.94412Z","iopub.status.idle":"2023-04-10T20:22:45.013705Z","shell.execute_reply.started":"2023-04-10T20:22:44.944085Z","shell.execute_reply":"2023-04-10T20:22:45.012669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:22:46.892424Z","iopub.execute_input":"2023-04-10T20:22:46.892839Z","iopub.status.idle":"2023-04-10T20:22:46.902486Z","shell.execute_reply.started":"2023-04-10T20:22:46.892806Z","shell.execute_reply":"2023-04-10T20:22:46.901385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:22:49.131649Z","iopub.execute_input":"2023-04-10T20:22:49.132238Z","iopub.status.idle":"2023-04-10T20:22:49.141677Z","shell.execute_reply.started":"2023-04-10T20:22:49.132185Z","shell.execute_reply":"2023-04-10T20:22:49.140246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalize the sensor response columns using MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf_train[['area', 'perimeter', 'dLx', 'dLy', 'a1', 'a2', 'AI', 'eccentricity', 'compactness_index', 'b1', 'd1', 'd2', 'equivalent_diameter', 'C_r', 'C_g', 'C_b', 'correlation', 'homogeneity', 'energy', 'contrast', 'color_count']] = scaler.fit_transform(df_train[['area', 'perimeter', 'dLx', 'dLy', 'a1', 'a2', 'AI', 'eccentricity', 'compactness_index', 'b1', 'd1', 'd2', 'equivalent_diameter', 'C_r', 'C_g', 'C_b', 'correlation', 'homogeneity', 'energy', 'contrast', 'color_count']])\n# Remove rows with missing values\ndf_train.dropna(inplace=True)\n\ndf_test[['area', 'perimeter', 'dLx', 'dLy', 'a1', 'a2', 'AI', 'eccentricity', 'compactness_index', 'b1', 'd1', 'd2', 'equivalent_diameter', 'C_r', 'C_g', 'C_b', 'correlation', 'homogeneity', 'energy', 'contrast', 'color_count']] = scaler.fit_transform(df_test[['area', 'perimeter', 'dLx', 'dLy', 'a1', 'a2', 'AI', 'eccentricity', 'compactness_index', 'b1', 'd1', 'd2', 'equivalent_diameter', 'C_r', 'C_g', 'C_b', 'correlation', 'homogeneity', 'energy', 'contrast', 'color_count']])\n# Remove rows with missing values\ndf_test.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:22:51.288466Z","iopub.execute_input":"2023-04-10T20:22:51.288929Z","iopub.status.idle":"2023-04-10T20:22:51.332534Z","shell.execute_reply.started":"2023-04-10T20:22:51.288863Z","shell.execute_reply":"2023-04-10T20:22:51.331166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.iloc[:,1:] #remove Unnamed: 0\ndf_test = df_test.iloc[:,1:]","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:22:54.403093Z","iopub.execute_input":"2023-04-10T20:22:54.403576Z","iopub.status.idle":"2023-04-10T20:22:54.411562Z","shell.execute_reply.started":"2023-04-10T20:22:54.403539Z","shell.execute_reply":"2023-04-10T20:22:54.410137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.columns","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:22:58.978367Z","iopub.execute_input":"2023-04-10T20:22:58.97874Z","iopub.status.idle":"2023-04-10T20:22:58.988672Z","shell.execute_reply.started":"2023-04-10T20:22:58.97871Z","shell.execute_reply":"2023-04-10T20:22:58.987402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:23:10.590711Z","iopub.execute_input":"2023-04-10T20:23:10.59125Z","iopub.status.idle":"2023-04-10T20:23:10.631903Z","shell.execute_reply.started":"2023-04-10T20:23:10.591203Z","shell.execute_reply":"2023-04-10T20:23:10.630757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:23:13.219453Z","iopub.execute_input":"2023-04-10T20:23:13.21983Z","iopub.status.idle":"2023-04-10T20:23:13.338093Z","shell.execute_reply.started":"2023-04-10T20:23:13.219799Z","shell.execute_reply":"2023-04-10T20:23:13.336967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:23:15.457654Z","iopub.execute_input":"2023-04-10T20:23:15.458333Z","iopub.status.idle":"2023-04-10T20:23:15.496038Z","shell.execute_reply.started":"2023-04-10T20:23:15.458264Z","shell.execute_reply":"2023-04-10T20:23:15.494762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.describe()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:23:19.858845Z","iopub.execute_input":"2023-04-10T20:23:19.859314Z","iopub.status.idle":"2023-04-10T20:23:19.945286Z","shell.execute_reply.started":"2023-04-10T20:23:19.859278Z","shell.execute_reply":"2023-04-10T20:23:19.94411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the distribution of dignosis classes\nplt.figure(figsize=(7,7))\nsns.countplot(data=df_train, x='dianosis', palette = \"Set2\")\nplt.title('Distribution of Diagnostic Classes')\nplt.savefig('distribution.png', dpi = 300)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:25:58.376317Z","iopub.execute_input":"2023-04-10T14:25:58.376791Z","iopub.status.idle":"2023-04-10T14:25:59.043444Z","shell.execute_reply.started":"2023-04-10T14:25:58.376753Z","shell.execute_reply":"2023-04-10T14:25:59.042068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# finding the correlation matrix\ncorrelation_matrix = df_train.corr()\ncorrelation_matrix.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:07:15.583654Z","iopub.execute_input":"2023-04-10T14:07:15.584317Z","iopub.status.idle":"2023-04-10T14:07:15.629978Z","shell.execute_reply.started":"2023-04-10T14:07:15.584259Z","shell.execute_reply":"2023-04-10T14:07:15.628191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore the correlation between Diagnosis Classes and other features\nplt.figure(figsize=(8,7))\nsns.heatmap(correlation_matrix, cmap='coolwarm')\nplt.title('Correlation Matrix')\nplt.savefig('coorelation.png', dpi = 300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:26:47.924144Z","iopub.execute_input":"2023-04-10T14:26:47.924654Z","iopub.status.idle":"2023-04-10T14:26:49.427696Z","shell.execute_reply.started":"2023-04-10T14:26:47.924602Z","shell.execute_reply":"2023-04-10T14:26:49.426441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining the threshold\n\n# get the correlation of target column (ProtocolName) with the rest of the columns\nsorted_corr_matrix_protocolName = correlation_matrix['dianosis'].sort_values(ascending=False)\nallKeys = sorted_corr_matrix_protocolName.keys()\n\npos_value_columns = []\n# printing the positive correlation value\nfor colName in allKeys:\n    print(sorted_corr_matrix_protocolName[colName], colName)\n    if (sorted_corr_matrix_protocolName[colName] > 0 and colName != 'dianosis'):\n        pos_value_columns.append(colName)\nprint(pos_value_columns)\nprint(len(pos_value_columns))","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:08:13.34177Z","iopub.execute_input":"2023-04-10T14:08:13.342382Z","iopub.status.idle":"2023-04-10T14:08:13.359125Z","shell.execute_reply.started":"2023-04-10T14:08:13.342337Z","shell.execute_reply":"2023-04-10T14:08:13.356948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=df_train[pos_value_columns]     #X-input features\ny_train=df_train['dianosis']\n\nX_test=df_test[pos_value_columns]     #X-input features\ny_test=df_test['dianosis']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:09:25.723076Z","iopub.execute_input":"2023-04-10T14:09:25.723598Z","iopub.status.idle":"2023-04-10T14:09:25.753481Z","shell.execute_reply.started":"2023-04-10T14:09:25.723559Z","shell.execute_reply":"2023-04-10T14:09:25.75167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define estimator for feature selection\nestimator = RandomForestClassifier(n_estimators=100, random_state=42)\n# KNeighborsClassifier(n_neighbors=21, weights='distance', metric='manhattan')\n# Define recursive feature elimination with cross-validation\nrfecv = RFECV(estimator=estimator, step=1, cv=5, scoring='accuracy')\n\n# Fit RFECV to training data\nrfecv.fit(X_train, y_train)\n\n# Print selected features\nprint(\"Selected Features: \", X_train.columns[rfecv.support_])\n\n# ['d1', 'dLy', 'dLx', 'area', 'contrast', 'C_g', 'perimeter', 'C_b', 'C_r']","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:10:26.698982Z","iopub.execute_input":"2023-04-10T14:10:26.699513Z","iopub.status.idle":"2023-04-10T14:11:15.174411Z","shell.execute_reply.started":"2023-04-10T14:10:26.699469Z","shell.execute_reply":"2023-04-10T14:11:15.172938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extra Trees Classifier\n\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n# Building the model\nextra_tree_forest = ExtraTreesClassifier(n_estimators = 50,criterion ='gini', max_features = 'log2')\n  \n# Training the model\nextra_tree_forest.fit(X_train, y_train)\n  \n# Computing the importance of each feature\nfeature_importance = extra_tree_forest.feature_importances_\n  \n# Normalizing the individual importances\nfeature_importance_normalized = np.std([tree.feature_importances_ for tree in \n                                        extra_tree_forest.estimators_],\n                                        axis = 0)\n\n# find out the best ones again and keep it here","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:12:51.897917Z","iopub.execute_input":"2023-04-10T14:12:51.899117Z","iopub.status.idle":"2023-04-10T14:12:52.120698Z","shell.execute_reply.started":"2023-04-10T14:12:51.899058Z","shell.execute_reply":"2023-04-10T14:12:52.119147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 0.01\n# split it up\nabove_threshold = np.maximum(feature_importance_normalized  - threshold, 0)\nbelow_threshold = np.minimum(feature_importance_normalized , threshold)\n\n# and plot it\nfig, ax = plt.subplots(figsize = (20,5))\nax.tick_params(labelrotation=90)\nax.set_xlabel('Feature Labels')\nax.set_ylabel('Feature Importances')\nax.set_title('Comparison of different Feature Importances')\nax.bar(X_train.columns, below_threshold)\nax.bar(X_train.columns, above_threshold, color=\"r\",bottom=below_threshold)\nfig.savefig('extratrees.png', dpi = 300)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:27:24.762813Z","iopub.execute_input":"2023-04-10T14:27:24.763313Z","iopub.status.idle":"2023-04-10T14:27:26.094261Z","shell.execute_reply.started":"2023-04-10T14:27:24.763275Z","shell.execute_reply":"2023-04-10T14:27:26.092885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_features = []\nfor i in range(len(X_train.columns)):\n    if below_threshold[i] == 0.01:\n        selected_features.append(X_train.columns[i])\nselected_features\n\n# ['d1','dLy','dLx','equivalent_diameter','area','contrast','C_g','perimeter','C_b','C_r','AI']","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:16:19.572795Z","iopub.execute_input":"2023-04-10T14:16:19.57331Z","iopub.status.idle":"2023-04-10T14:16:19.583817Z","shell.execute_reply.started":"2023-04-10T14:16:19.573268Z","shell.execute_reply":"2023-04-10T14:16:19.582433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfecv = list(X_train.columns[rfecv.support_])\n\n# Python program to illustrate the intersection of two lists in most simple way\ndef intersection(lst1, lst2):\n    lst3 = [value for value in lst1 if value in lst2]\n    return lst3\n \nfeatures = intersection(selected_features,rfecv)\nfeatures\n\n# ['d1', 'dLy', 'dLx', 'area', 'contrast', 'C_g', 'perimeter', 'C_b', 'C_r']","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:16:58.753166Z","iopub.execute_input":"2023-04-10T14:16:58.753848Z","iopub.status.idle":"2023-04-10T14:16:58.765824Z","shell.execute_reply.started":"2023-04-10T14:16:58.753794Z","shell.execute_reply":"2023-04-10T14:16:58.764831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['d1', 'dLy', 'dLx', 'area', 'contrast', 'C_g', 'perimeter', 'C_b', 'C_r']","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:23:43.389138Z","iopub.execute_input":"2023-04-10T20:23:43.389568Z","iopub.status.idle":"2023-04-10T20:23:43.396174Z","shell.execute_reply.started":"2023-04-10T20:23:43.389533Z","shell.execute_reply":"2023-04-10T20:23:43.394845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xf_train = df_train[features]\nyf_train = df_train['dianosis']\n\nXf_test = df_test[features]\nyf_test = df_test['dianosis']","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:23:45.266565Z","iopub.execute_input":"2023-04-10T20:23:45.267044Z","iopub.status.idle":"2023-04-10T20:23:45.275563Z","shell.execute_reply.started":"2023-04-10T20:23:45.267Z","shell.execute_reply":"2023-04-10T20:23:45.273965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xf_train","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:23:49.046494Z","iopub.execute_input":"2023-04-10T20:23:49.046869Z","iopub.status.idle":"2023-04-10T20:23:49.070008Z","shell.execute_reply.started":"2023-04-10T20:23:49.04684Z","shell.execute_reply":"2023-04-10T20:23:49.06892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Use heatmap to see corelation between variables\nplt.figure(figsize = (12,10))\nsns.heatmap(Xf_train.corr(),annot=True,cmap='viridis')\nplt.title('Heatmap of co-relation between variables',fontsize=2)\nplt.savefig('coorelation_heatmap.png', dpi = 300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:32:18.442614Z","iopub.execute_input":"2023-04-10T14:32:18.443059Z","iopub.status.idle":"2023-04-10T14:32:20.356789Z","shell.execute_reply.started":"2023-04-10T14:32:18.443023Z","shell.execute_reply":"2023-04-10T14:32:20.355115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Models**","metadata":{}},{"cell_type":"code","source":"# use GridSearchCV to tune the hyperparameters for the meta-learners\n\n\n# Define the models to evaluate\nmodels = {\n    'Logistic Regression': LogisticRegression(random_state=42),\n    'Random Forest': RandomForestClassifier(random_state=42),\n    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n    'Support Vector Machines': SVC(random_state=42),\n    'K-Neighbors': KNeighborsClassifier(),\n    'Decision Tree': DecisionTreeClassifier(random_state=42),\n    'Cat Boost': CatBoostClassifier(random_state=42),\n    'XGB': XGBClassifier(random_state=42)\n}\n    \n# Define the hyperparameters to tune for each model\nparams = {\n    'Logistic Regression': {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n    'Random Forest': {'n_estimators': [10, 50, 100, 250, 500], 'max_depth': [5, 10, 20]},\n    'Gradient Boosting': {'n_estimators': [10, 50, 100, 250, 500], 'learning_rate': [0.0005, 0.0001, 0.005, 0.001, 0.01, 0.1]},\n    'Support Vector Machines': {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['linear', 'rbf']},\n    'K-Neighbors': { 'n_neighbors': [3, 5, 7, 11, 21], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']},\n    'Decision Tree': {'max_features': ['auto'],'ccp_alpha': [0.1, .01, .001],'max_depth' : [5, 10, 20],'criterion' :['gini', 'entropy']},\n    'Cat Boost': {'iterations': [50,500,5000], 'max_depth': [5, 10, 20], 'loss_function': ['Logloss', 'CrossEntropy', 'MultiClass', 'MultiClassOneVsAll'], 'learning_rate': [0.0005, 0.0001, 0.005, 0.001, 0.01, 0.1], 'eval_metric': ['AUC']},\n    'XGB': {'max_depth': [5, 10, 20], 'n_estimators': [10, 50, 100, 250, 500], 'learning_rate': [0.0005, 0.0001, 0.005, 0.001, 0.01, 0.1]}  \n}\n    \n# Create a list to store the results of each model\nresults = []\n    \n# Loop through each model and perform GridSearchCV\nfor name, model in models.items():\n    clf = RandomizedSearchCV(model, params[name], cv=3, scoring='accuracy', n_jobs = -1)\n    # fit the meta learner\n    clf.fit(Xf_train, yf_train)\n    \n# Add the model name and best accuracy score to the results list\nresults.append({'model': name, 'best_score': clf.best_score_, 'best_params': clf.best_params_})\n\n# Print the results for each model\nfor result in results:\n    print(f\"{result['model']}: Best score = {result['best_score']:.4f}, Best params = {result['best_params']}\")\n    \n# K-Nearest: Best score = 0.7478, Best params = {'metric': 'manhattan', 'n_neighbors': 21, 'weights': 'distance'}\n# XGB: Best score = 0.7774, Best params = {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.1}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# xgb = XGBClassifier(random_state=42, n_estimators=10, max_depth=20, learning_rate=0.0005)\nxgb = XGBClassifier(random_state=42, n_estimators=500, max_depth=5, learning_rate=0.1)\nxgb.fit(Xf_train,yf_train)\n\n# save the model to disk\nfilename = 'xgb_model.sav'\npickle.dump(xgb, open(filename, 'wb'))\n\ny_pred_xgb = xgb.predict(Xf_test)\nprint(metrics.accuracy_score(yf_test, y_pred_xgb))","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:50:37.788412Z","iopub.execute_input":"2023-04-10T14:50:37.788883Z","iopub.status.idle":"2023-04-10T14:50:41.341486Z","shell.execute_reply.started":"2023-04-10T14:50:37.788845Z","shell.execute_reply":"2023-04-10T14:50:41.339783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Individual Tunining**","metadata":{}},{"cell_type":"code","source":"params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'solver': ['newton-cg', 'lbfgs', 'liblinear']}\nlr = RandomizedSearchCV(LogisticRegression(random_state=42), params, cv = 3, n_jobs=-1)\nlr.fit(Xf_train, yf_train)\nprint(lr.best_score_)\nprint(lr.best_params_)\n\nypred = lr.predict(Xf_test)\nprint(\"Testing: \",metrics.accuracy_score(yf_test, ypred))\n\n# save the model to disk\nfilename = 'lr_model.sav'\npickle.dump(lr, open(filename, 'wb'))\n\n\n# 0.7755024649222602 {'solver': 'liblinear', 'C': 1000}\n# Testing:  0.7287878787878788","metadata":{"execution":{"iopub.status.busy":"2023-04-10T17:00:41.135188Z","iopub.execute_input":"2023-04-10T17:00:41.135636Z","iopub.status.idle":"2023-04-10T17:00:41.379338Z","shell.execute_reply.started":"2023-04-10T17:00:41.135597Z","shell.execute_reply":"2023-04-10T17:00:41.378476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'n_estimators': [10, 50, 100, 250, 500], 'max_depth': [5, 10, 20]}\nrf = RandomizedSearchCV(RandomForestClassifier(random_state=42), params, cv = 3, n_jobs=-1)\nrf.fit(Xf_train, yf_train)\nprint(rf.best_score_)\nprint(rf.best_params_)\n\nypred = rf.predict(Xf_test)\nprint(\"Testing: \",metrics.accuracy_score(yf_test, ypred))\n\n# save the model to disk\nfilename = 'rf_model.sav'\npickle.dump(rf, open(filename, 'wb'))\n\n# 0.7682973075464542 {'n_estimators': 500, 'max_depth': 20}\n# Testing:  0.7560606060606061","metadata":{"execution":{"iopub.status.busy":"2023-04-10T17:00:46.416294Z","iopub.execute_input":"2023-04-10T17:00:46.417622Z","iopub.status.idle":"2023-04-10T17:01:00.098092Z","shell.execute_reply.started":"2023-04-10T17:00:46.417561Z","shell.execute_reply":"2023-04-10T17:01:00.097026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params =  {'n_neighbors': [3, 5, 7, 11, 21], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']}\nknn = RandomizedSearchCV(KNeighborsClassifier(), params, cv = 3,  n_jobs=-1)\nknn.fit(Xf_train, yf_train)\nprint(knn.best_score_)\nprint(knn.best_params_)\n\nypred = knn.predict(Xf_test)\nprint(\"Testing: \",metrics.accuracy_score(yf_test, ypred))\n\n# save the model to disk\nfilename = 'knn_model.sav'\npickle.dump(knn, open(filename, 'wb'))\n\n# 0.7398558968524839 {'weights': 'distance', 'n_neighbors': 11, 'metric': 'manhattan'}\n# Testing:  0.7545454545454545","metadata":{"execution":{"iopub.status.busy":"2023-04-10T17:02:49.190554Z","iopub.execute_input":"2023-04-10T17:02:49.191067Z","iopub.status.idle":"2023-04-10T17:02:51.263972Z","shell.execute_reply.started":"2023-04-10T17:02:49.19102Z","shell.execute_reply":"2023-04-10T17:02:51.262858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'max_features': ['auto'],'ccp_alpha': [0.1, .01, .001],'max_depth' : [5, 10, 20],'criterion' :['gini', 'entropy']},\ndt = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params, cv = 3, n_jobs=-1)\ndt.fit(Xf_train, yf_train)\nprint(dt.best_score_)\nprint(dt.best_params_)\n\nypred = dt.predict(Xf_test)\nprint(\"Testing: \",metrics.accuracy_score(yf_test, ypred))\n\n# save the model to disk\nfilename = 'dt_model.sav'\npickle.dump(dt, open(filename, 'wb'))\n\n# 0.7171027682973076 {'max_features': 'auto', 'max_depth': 5, 'criterion': 'entropy', 'ccp_alpha': 0.001}\n# Testing:  0.7106060606060606","metadata":{"execution":{"iopub.status.busy":"2023-04-10T17:03:30.546995Z","iopub.execute_input":"2023-04-10T17:03:30.548222Z","iopub.status.idle":"2023-04-10T17:03:30.780931Z","shell.execute_reply.started":"2023-04-10T17:03:30.548138Z","shell.execute_reply":"2023-04-10T17:03:30.779911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'iterations': [50,500,5000], 'max_depth': [5, 10, 20], 'loss_function': ['Logloss', 'CrossEntropy', 'MultiClass', 'MultiClassOneVsAll'], 'learning_rate': [0.0005, 0.0001, 0.005, 0.001, 0.01, 0.1], 'eval_metric': ['AUC']}\ncat = RandomizedSearchCV(CatBoostClassifier(random_state=42), params, cv = 3, n_jobs=-1)\ncat.fit(Xf_train, yf_train)\nprint(cat.best_score_)\nprint(cat.best_params_)\n\nypred = cat.predict(Xf_test)\nprint(\"Testing: \",metrics.accuracy_score(yf_test, ypred))\n\n# save the model to disk\nfilename = 'cat_model.sav'\npickle.dump(cat, open(filename, 'wb'))\n\n# 0.7808115282518013 {'max_depth': 5, 'loss_function': 'Logloss', 'learning_rate': 0.1, 'iterations': 500, 'eval_metric': 'AUC'}\n# Testing:  0.7621212121212121","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'max_depth': [5, 10, 20], 'n_estimators': [10, 50, 100, 250, 500], 'learning_rate': [0.0005, 0.0001, 0.005, 0.001, 0.01, 0.1]}\nxgb = RandomizedSearchCV(XGBClassifier(random_state=42), params, cv = 3, n_jobs=-1)\nxgb.fit(Xf_train, yf_train)\nprint(xgb.best_score_)\nprint(xgb.best_params_)\n\nypred = xgb.predict(Xf_test)\nprint(\"Testing: \",metrics.accuracy_score(yf_test, ypred))\n\n# save the model to disk\nfilename = 'xgb_model.sav'\npickle.dump(xgb, open(filename, 'wb'))\n\n# 0.7849829351535836 {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.1}\n# Testing:  0.753030303030303","metadata":{"execution":{"iopub.status.busy":"2023-04-10T17:18:58.718452Z","iopub.execute_input":"2023-04-10T17:18:58.718773Z","iopub.status.idle":"2023-04-10T17:19:31.664494Z","shell.execute_reply.started":"2023-04-10T17:18:58.718743Z","shell.execute_reply":"2023-04-10T17:19:31.663505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'n_estimators': [10, 50, 100, 250, 500], 'learning_rate': [0.0005, 0.0001, 0.005, 0.001, 0.01, 0.1]}\ngbc = RandomizedSearchCV(GradientBoostingClassifier(random_state=42), params, cv = 3, n_jobs=-1)\ngbc.fit(Xf_train, yf_train)\nprint(gbc.best_score_)\nprint(gbc.best_params_)\n\nypred = gbc.predict(Xf_test)\nprint(\"Testing: \",metrics.accuracy_score(yf_test, ypred))\n\n# save the model to disk\nfilename = 'gbc_model.sav'\npickle.dump(gbc, open(filename, 'wb'))\n\n# 0.7796738718240425 {'n_estimators': 250, 'learning_rate': 0.1}\n# Testing:  0.7575757575757576","metadata":{"execution":{"iopub.status.busy":"2023-04-10T17:39:39.323978Z","iopub.execute_input":"2023-04-10T17:39:39.324447Z","iopub.status.idle":"2023-04-10T17:39:48.130883Z","shell.execute_reply.started":"2023-04-10T17:39:39.32441Z","shell.execute_reply":"2023-04-10T17:39:48.129358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['linear', 'rbf']}\nsvc = RandomizedSearchCV(SVC(random_state=42), params, cv = 3, n_jobs=-1)\nsvc.fit(Xf_train, yf_train)\nprint(svc.best_score_)\nprint(svc.best_params_)\n\nypred = svc.predict(Xf_test)\nprint(\"Testing: \",metrics.accuracy_score(yf_test, ypred))\n\n# save the model to disk \nfilename = 'svc_model.sav'\npickle.dump(svc, open(filename, 'wb'))\n\n# 0.7982555934774366 {'kernel': 'rbf', 'C': 100}\n# Testing:  0.7545454545454545","metadata":{"execution":{"iopub.status.busy":"2023-04-10T17:41:18.742849Z","iopub.execute_input":"2023-04-10T17:41:18.743363Z","iopub.status.idle":"2023-04-10T17:41:22.582272Z","shell.execute_reply.started":"2023-04-10T17:41:18.743294Z","shell.execute_reply":"2023-04-10T17:41:22.581007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nconfusion_matrix = metrics.confusion_matrix(yf_test, y_pred_xgb)\n\nplt.figure(figsize=(8,6))\nfx=sns.heatmap(confusion_matrix, annot=True, fmt=\".2f\",cmap=\"GnBu\")\nfx.set_title('Confusion Matrix \\n');\nfx.set_xlabel('\\n Predicted Values\\n')\nfx.set_ylabel('Actual Values\\n')\nlabels = ['Benign','Malignant']\nfx.xaxis.set_ticklabels(labels, rotation=90)\nfx.yaxis.set_ticklabels(labels, rotation=0)\n#plt.savefig('confusionmatrix.png', dpi = 300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:55:27.462807Z","iopub.execute_input":"2023-04-10T14:55:27.463438Z","iopub.status.idle":"2023-04-10T14:55:28.335397Z","shell.execute_reply.started":"2023-04-10T14:55:27.463394Z","shell.execute_reply":"2023-04-10T14:55:28.334024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification Report\n\nprint(metrics.classification_report(yf_test, y_pred_xgb))","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:55:55.931721Z","iopub.execute_input":"2023-04-10T14:55:55.932233Z","iopub.status.idle":"2023-04-10T14:55:55.94775Z","shell.execute_reply.started":"2023-04-10T14:55:55.932191Z","shell.execute_reply":"2023-04-10T14:55:55.946043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification Report\n\nprint(metrics.classification_report(yf_test, y_pred_xgb))\n\n#accuracy on test set\nresult = xgb.score(Xf_test, yf_test)\nprint(\"Accuracy - test set: %.2f%%\" % (result*100.0))\n\n#precision on test set\nprecision = precision_score(yf_test, y_pred_xgb)\nprint('Precision: %f' % precision)\n\n# recall: tp / (tp + fn)\nrecall = recall_score(yf_test, y_pred_xgb)\nprint('Recall: %f' % recall)\n\n# f1: tp / (tp + fp + fn)\nf1 = f1_score(yf_test, y_pred_xgb)\nprint('F1 score: %f' % f1)\n\n# ROC curve\n# predict probabilities\nprobs = xgb.predict_proba(Xf_test)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n\nauc = roc_auc_score(yf_test, probs)\nprint('AUC - Test Set: %.2f%%' % (auc*100))\n\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(yf_test, probs)\n# plot no skill\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('False positive rate')\nplt.ylabel('Sensitivity/ Recall')\n#plt.savefig('auc_roc.png', dpi=300)\n# show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:58:53.053765Z","iopub.execute_input":"2023-04-10T14:58:53.054246Z","iopub.status.idle":"2023-04-10T14:58:53.643219Z","shell.execute_reply.started":"2023-04-10T14:58:53.054191Z","shell.execute_reply":"2023-04-10T14:58:53.641654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **RNN**\n\nI used the Keras Sequential API, where you have just to add one layer at a time, starting from the input.\n\nThe first is the convolutional (Conv2D) layer. It is like a set of learnable filters. I choosed to set 64 filters for the two firsts conv2D layers. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n\nThe CNN can isolate features that are useful everywhere from these transformed images (feature maps).\n\nThe second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is high, more the downsampling is important.\n\nCombining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.\n\nDropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting.\n\n'relu' is the rectifier (activation function max(0,x). The rectifier activation function is used to add non linearity to the network.\n\nThe Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional/maxpool layers. It combines all the found local features of the previous convolutional layers.\n\nIn the end i used the features in one fully-connected (Dense) layer which is just artificial an neural networks (ANN) classifier.","metadata":{}},{"cell_type":"code","source":"Xf_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-10T15:00:10.591539Z","iopub.execute_input":"2023-04-10T15:00:10.592233Z","iopub.status.idle":"2023-04-10T15:00:10.602762Z","shell.execute_reply.started":"2023-04-10T15:00:10.592174Z","shell.execute_reply":"2023-04-10T15:00:10.600699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LeakyReLU\nfrom tensorflow.keras.optimizers import Adamax, Adam\nfrom tensorflow.keras import regularizers\n\n# Define the model architecture\ndef create_model(neurons, dropout_rate, kernel_regularizer, learning_rate):\n    input_shape = (Xf_train.shape[1],)\n    model = Sequential()\n    model.add(Dense(neurons, activation='relu', input_shape=input_shape))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(neurons//2, activation='relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(neurons//4, activation='relu', kernel_regularizer=regularizers.l2(kernel_regularizer)))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(neurons//8, activation='relu', kernel_regularizer=regularizers.l2(kernel_regularizer)))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(neurons//16, activation='relu', kernel_regularizer=regularizers.l2(kernel_regularizer)))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(neurons/32, activation='relu', kernel_regularizer=regularizers.l2(kernel_regularizer)))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(1, activation='sigmoid'))\n    opt = Adam(learning_rate=learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n\n    return model\n\n# Create the KerasClassifier wrapper for scikit-learn\nmodel = KerasClassifier(build_fn=create_model, verbose=0)\n\n# Define the hyperparameters search space\nneurons = [64, 128, 256, 512, 1024]\ndropout_rate = [0, 0.25, 0.5, 0.75]\nkernel_regularizer = [0.01, 0.001, 0.0001]\nlearning_rate = [0.0005, 0.0001, 0.005, 0.001, 0.01, 0.1]\nbatch_size = [16, 32, 64]\nepochs = [50, 100, 150, 300]\n\nparam_grid = dict(neurons=neurons, dropout_rate=dropout_rate, kernel_regularizer=kernel_regularizer, learning_rate=learning_rate, batch_size=batch_size, epochs=epochs)\n\n# Perform the randomized search with cross-validation\nn_iter_search = 50\nrandom_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=n_iter_search, cv=3, n_jobs = -1)\nrandom_search.fit(Xf_train, yf_train, validation_data = (Xf_test, yf_test))\n\n# Print the best parameters and score\nprint(\"Best parameters: \", random_search.best_params_)\nprint(\"Best score: \", random_search.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LeakyReLU\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras import regularizers\n\n# Define the parameters\n\nneurons = 1024\ndropout_rate = 0.25\nkernel_regularizer = 0.001\nlearning_rate = 0.00001\nbatch_size = 16\nepochs = 300\n\ninput_shape = (Xf_train.shape[1],)\nmodel = Sequential()\nmodel.add(Dense(neurons, activation='relu', input_shape=input_shape))\nmodel.add(Dropout(dropout_rate))\nmodel.add(Dense(neurons//2, activation='relu'))\nmodel.add(Dropout(dropout_rate))\nmodel.add(Dense(neurons//4, activation='relu'))\nmodel.add(Dropout(dropout_rate))\nmodel.add(Dense(neurons//8, activation='relu'))\nmodel.add(Dropout(dropout_rate))\nmodel.add(Dense(neurons//16, activation='relu'))\nmodel.add(Dropout(dropout_rate))\nmodel.add(Dense(neurons/32, activation='relu', kernel_regularizer=regularizers.l2(kernel_regularizer)))\nmodel.add(Dropout(dropout_rate))\nmodel.add(Dense(1, activation='sigmoid'))\n\nopt = Adam(learning_rate=learning_rate)\nmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'],)\n\n\nhistory = model.fit(Xf_train, yf_train, validation_data = (Xf_test, yf_test), epochs=epochs, batch_size=batch_size) #, callbacks=[tf.keras.callbacks.ReduceLROnPlateau()])","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:03:53.03225Z","iopub.execute_input":"2023-04-10T19:03:53.033094Z","iopub.status.idle":"2023-04-10T19:10:05.365742Z","shell.execute_reply.started":"2023-04-10T19:03:53.033035Z","shell.execute_reply":"2023-04-10T19:10:05.364151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# You can also plot the model architecture using `plot_model`\nplot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T18:54:31.056157Z","iopub.execute_input":"2023-04-10T18:54:31.056618Z","iopub.status.idle":"2023-04-10T18:54:32.25994Z","shell.execute_reply.started":"2023-04-10T18:54:31.056576Z","shell.execute_reply":"2023-04-10T18:54:32.258368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('model accuracy.png', dpi = 300)\nplt.show()\n\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['loss'])\nplt.title('model accuracy vs loss')\nplt.xlabel('epoch')\nplt.legend(['accuracy', 'loss'], loc='upper left')\nplt.savefig('model accuracy vs loss.png', dpi = 300)\nplt.show()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('model loss.png', dpi = 300)\nplt.show()\n\n# summarize history for accuracy\nplt.plot(history.history['val_accuracy'])\nplt.plot(history.history['val_loss'])\nplt.title('model validation accuracy vs loss')\nplt.xlabel('epoch')\nplt.legend(['val_accuracy', 'val_loss'], loc='upper left')\nplt.savefig('model validation accuracy.png', dpi = 300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:10:05.368449Z","iopub.execute_input":"2023-04-10T19:10:05.368903Z","iopub.status.idle":"2023-04-10T19:10:07.149331Z","shell.execute_reply.started":"2023-04-10T19:10:05.368859Z","shell.execute_reply":"2023-04-10T19:10:07.147902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save('featureRNN.h5')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:10:07.151327Z","iopub.execute_input":"2023-04-10T19:10:07.15215Z","iopub.status.idle":"2023-04-10T19:10:07.213335Z","shell.execute_reply.started":"2023-04-10T19:10:07.152098Z","shell.execute_reply":"2023-04-10T19:10:07.212396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('/kaggle/input/skincancer-keras-cnn/featureRNN.h5')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:15:22.226721Z","iopub.execute_input":"2023-04-10T19:15:22.229079Z","iopub.status.idle":"2023-04-10T19:15:22.684179Z","shell.execute_reply.started":"2023-04-10T19:15:22.228989Z","shell.execute_reply":"2023-04-10T19:15:22.682088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_proba = model.predict(Xf_test)\n# Apply a threshold of 0.5 to obtain the predicted class labels\nthreshold = 0.5\ny_pred = (y_pred_proba > threshold).astype(int).flatten()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:17:56.660822Z","iopub.execute_input":"2023-04-10T19:17:56.66248Z","iopub.status.idle":"2023-04-10T19:17:56.797968Z","shell.execute_reply.started":"2023-04-10T19:17:56.662412Z","shell.execute_reply":"2023-04-10T19:17:56.79684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification Report\n\nprint(metrics.classification_report(yf_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:17:59.975879Z","iopub.execute_input":"2023-04-10T19:17:59.976349Z","iopub.status.idle":"2023-04-10T19:17:59.991756Z","shell.execute_reply.started":"2023-04-10T19:17:59.976314Z","shell.execute_reply":"2023-04-10T19:17:59.990249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the distribution of RH_type classes\ndf_y_pred = pd.DataFrame(y_pred, columns=['Predicted Diagnosis'])\ndf_y_test = pd.DataFrame(list(yf_test), columns=['Actual Diagnosis'])\n\nfig, ax =plt.subplots(1,2, figsize=(15,5))\nsns.countplot (x = df_y_test['Actual Diagnosis'], palette = \"Set2\", ax=ax[0])\nsns.countplot (x = df_y_pred['Predicted Diagnosis'], palette = \"Set2\", ax=ax[1])\nfig.savefig('predicted diagnosis.png', dpi = 300)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:19:37.503735Z","iopub.execute_input":"2023-04-10T19:19:37.504305Z","iopub.status.idle":"2023-04-10T19:19:38.363258Z","shell.execute_reply.started":"2023-04-10T19:19:37.50426Z","shell.execute_reply":"2023-04-10T19:19:38.361862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nconfusion_matrix = metrics.confusion_matrix(yf_test, y_pred)\n\nplt.figure(figsize=(8,6))\nfx=sns.heatmap(confusion_matrix, annot=True, fmt=\".2f\",cmap=\"GnBu\")\nfx.set_title('Confusion Matrix \\n');\nfx.set_xlabel('\\n Predicted Values\\n')\nfx.set_ylabel('Actual Values\\n')\nlabels = ['Benign','Malignant']\nfx.xaxis.set_ticklabels(labels, rotation=90)\nfx.yaxis.set_ticklabels(labels, rotation=0)\nplt.savefig('confusionmatrix.png', dpi = 300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:20:53.709631Z","iopub.execute_input":"2023-04-10T19:20:53.710151Z","iopub.status.idle":"2023-04-10T19:20:54.345587Z","shell.execute_reply.started":"2023-04-10T19:20:53.710106Z","shell.execute_reply":"2023-04-10T19:20:54.344207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification Report\n\nprint(metrics.classification_report(yf_test, y_pred))\n\n#accuracy on test set\nresult = xgb.score(Xf_test, yf_test)\nprint(\"Accuracy - test set: %.2f%%\" % (result*100.0))\n\n#precision on test set\nprecision = precision_score(yf_test, y_pred)\nprint('Precision: %f' % precision)\n\n# recall: tp / (tp + fn)\nrecall = recall_score(yf_test, y_pred)\nprint('Recall: %f' % recall)\n\n# f1: tp / (tp + fp + fn)\nf1 = f1_score(yf_test, y_pred)\nprint('F1 score: %f' % f1)\n\n# ROC curve\n# predict probabilities\nprobs = xgb.predict_proba(Xf_test)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n\nauc = roc_auc_score(yf_test, probs)\nprint('AUC - Test Set: %.2f%%' % (auc*100))\n\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(yf_test, probs)\n# plot no skill\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('False positive rate')\nplt.ylabel('Sensitivity/ Recall')\nplt.savefig('auc_roc.png', dpi=300)\n# show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:22:38.01345Z","iopub.execute_input":"2023-04-10T19:22:38.01525Z","iopub.status.idle":"2023-04-10T19:22:38.610017Z","shell.execute_reply.started":"2023-04-10T19:22:38.015191Z","shell.execute_reply":"2023-04-10T19:22:38.607426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Stacked Ensemble**","metadata":{}},{"cell_type":"code","source":"rf = pickle.load(open('/kaggle/input/skincancer-keras-cnn/Features_sklearn_models/rf_model.sav', 'rb'))\nkn = pickle.load(open('/kaggle/input/skincancer-keras-cnn/Features_sklearn_models/knn_model.sav', 'rb'))\nxgb = pickle.load(open('/kaggle/input/skincancer-keras-cnn/Features_sklearn_models/xgb_model.sav', 'rb'))\ngbc = pickle.load(open('/kaggle/input/skincancer-keras-cnn/Features_sklearn_models/gbc_model.sav', 'rb'))\ncat = pickle.load(open('/kaggle/input/skincancer-keras-cnn/Features_sklearn_models/cat_model.sav', 'rb'))\nsvc = pickle.load(open('/kaggle/input/skincancer-keras-cnn/Features_sklearn_models/svc_model.sav', 'rb'))\nrnn = load_model('/kaggle/input/skincancer-keras-cnn/featureRNN.h5')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:26:00.854079Z","iopub.execute_input":"2023-04-10T20:26:00.854478Z","iopub.status.idle":"2023-04-10T20:26:01.255047Z","shell.execute_reply.started":"2023-04-10T20:26:00.854446Z","shell.execute_reply":"2023-04-10T20:26:01.253572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_rf = rf.predict(Xf_test)\ny_pred_kn = kn.predict(Xf_test)\ny_pred_cat = cat.predict(Xf_test)\ny_pred_xgb = xgb.predict(Xf_test)\ny_pred_gbc = gbc.predict(Xf_test)\ny_pred_svc = svc.predict(Xf_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:26:03.45303Z","iopub.execute_input":"2023-04-10T20:26:03.453868Z","iopub.status.idle":"2023-04-10T20:26:03.711667Z","shell.execute_reply.started":"2023-04-10T20:26:03.45382Z","shell.execute_reply":"2023-04-10T20:26:03.710346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred = list(rnn.predict(Xf_test))\ny_pred = list(rnn.predict(Xf_test))\nprint(type(y_pred))\ny_pred_rnn = []\nfor i in range(len(y_pred)):\n    a = list(y_pred[i])\n    maxpos = a.index(max(a))\n    y_pred_rnn.append(maxpos)\n\ny_pred_rnn = np.array(y_pred_rnn)\ny_pred_rnn.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:26:06.266425Z","iopub.execute_input":"2023-04-10T20:26:06.266824Z","iopub.status.idle":"2023-04-10T20:26:06.822663Z","shell.execute_reply.started":"2023-04-10T20:26:06.266791Z","shell.execute_reply":"2023-04-10T20:26:06.82135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred_cat = y_pred_cat.reshape(y_pred_cat.shape[0],)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_pred_rf.shape)\nprint(y_pred_kn.shape)\nprint(y_pred_xgb.shape)\nprint(y_pred_gbc.shape)\nprint(y_pred_cat.shape)\nprint(y_pred_svc.shape)\nprint(y_pred_rnn.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:26:08.964966Z","iopub.execute_input":"2023-04-10T20:26:08.9654Z","iopub.status.idle":"2023-04-10T20:26:08.972688Z","shell.execute_reply.started":"2023-04-10T20:26:08.965362Z","shell.execute_reply":"2023-04-10T20:26:08.971192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_y_pred = np.stack((y_pred_rf, y_pred_kn, y_pred_xgb, y_pred_gbc,y_pred_cat, y_pred_svc, y_pred_rnn), axis=1)\ncombined_y_pred.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:26:12.454164Z","iopub.execute_input":"2023-04-10T20:26:12.454719Z","iopub.status.idle":"2023-04-10T20:26:12.466453Z","shell.execute_reply.started":"2023-04-10T20:26:12.454667Z","shell.execute_reply":"2023-04-10T20:26:12.46492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stackedX = combined_y_pred","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:26:17.242017Z","iopub.execute_input":"2023-04-10T20:26:17.242849Z","iopub.status.idle":"2023-04-10T20:26:17.248663Z","shell.execute_reply.started":"2023-04-10T20:26:17.242791Z","shell.execute_reply":"2023-04-10T20:26:17.247813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stackedX.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:26:19.693109Z","iopub.execute_input":"2023-04-10T20:26:19.693515Z","iopub.status.idle":"2023-04-10T20:26:19.701188Z","shell.execute_reply.started":"2023-04-10T20:26:19.693481Z","shell.execute_reply":"2023-04-10T20:26:19.700035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yf_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:26:21.976822Z","iopub.execute_input":"2023-04-10T20:26:21.977385Z","iopub.status.idle":"2023-04-10T20:26:21.986987Z","shell.execute_reply.started":"2023-04-10T20:26:21.977333Z","shell.execute_reply":"2023-04-10T20:26:21.985532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use GridSearchCV to tune the hyperparameters for the meta-learners\n\ndef fit_stacked_model(stackedX, inputX, inputy):\n    # create dataset using ensemble    \n    # create dataset using ensemble'\n    # stackedX = stacked_dataset(members, inputX)\n    # Define the models to evaluate\n    models = {        \n        'Logistic Regression': LogisticRegression(random_state=42),\n        'Random Forest': RandomForestClassifier(random_state=42),\n        'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n        'K-Nearest': KNeighborsClassifier(),\n        'Decision Tree': DecisionTreeClassifier(random_state=42),\n        'Cat Boost': CatBoostClassifier(random_state=42),\n        'Support Vector Machines': SVC(random_state=42),\n        'XGB': XGBClassifier(random_state=42) \n    }\n    \n    # Define the hyperparameters to tune for each model\n    params = {\n        'Logistic Regression': {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n        'Random Forest': {'n_estimators': [10, 50, 100, 250, 500], 'max_depth': [5, 10, 20]},\n        'Gradient Boosting': {'n_estimators': [10, 50, 100, 250, 500], 'learning_rate': [[ 0.001, 0.005, 0.0001, 0.0005]]},\n        'K-Nearest': {'n_neighbors': [3, 5, 7, 11, 21], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']},\n        'Decision Tree': {'max_features': ['auto'],'ccp_alpha': [0.1, .01, .001],'max_depth' : [5, 10, 20],'criterion' :['gini', 'entropy']},\n        'Cat Boost': {'iterations': [50,500,5000], 'max_depth': [5, 10, 20], 'loss_function': ['MultiClass'],  'learning_rate': [ 0.001, 0.005, 0.0001, 0.0005], 'eval_metric': ['MultiClass']},\n        'Support Vector Machines': {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['linear', 'rbf']},\n        'XGB': {'max_depth': [5, 10, 20], 'n_estimators': [10, 50, 100, 250, 500], 'learning_rate': [0.0005, 0.0001, 0.005, 0.001, 0.01, 0.1]}  \n    }\n    \n    # Create a list to store the results of each model\n    results = []\n    \n    # Loop through each model and perform GridSearchCV\n    for name, model in models.items():\n        clf = RandomizedSearchCV(model, params[name], cv=5,  n_jobs=-1, scoring='accuracy')\n        # fit the meta learner\n        clf.fit(stackedX, inputy)\n    \n    # Add the model name and best accuracy score to the results list\n    results.append({'model': name, 'best_score': clf.best_score_, 'best_params': clf.best_params_})\n\n    # Print the results for each model\n    for result in results:\n        print(f\"{result['model']}: Best score = {result['best_score']:.4f}, Best params = {result['best_params']}\")\n    \n    return clf\n\nmodel = fit_stacked_model(stackedX, Xf_test,yf_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stacked meta learner\n\nmodel = XGBClassifier(n_estimators=500, max_depth=5, learning_rate=0.1)\nmodel.fit(stackedX,yf_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:26:28.14496Z","iopub.execute_input":"2023-04-10T20:26:28.145359Z","iopub.status.idle":"2023-04-10T20:26:30.308928Z","shell.execute_reply.started":"2023-04-10T20:26:28.145326Z","shell.execute_reply":"2023-04-10T20:26:30.307968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make a prediction with the stacked model\ndef stacked_prediction(model, stackedX):\n    y_pred = model.predict(stackedX)\n    return y_pred\n\n# evaluate model on test set -\ny_pred = stacked_prediction(model, stackedX)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:26:32.301415Z","iopub.execute_input":"2023-04-10T20:26:32.30252Z","iopub.status.idle":"2023-04-10T20:26:32.316243Z","shell.execute_reply.started":"2023-04-10T20:26:32.302475Z","shell.execute_reply":"2023-04-10T20:26:32.314507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification Report\n\nprint(metrics.classification_report(yf_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:26:34.98817Z","iopub.execute_input":"2023-04-10T20:26:34.988569Z","iopub.status.idle":"2023-04-10T20:26:35.002526Z","shell.execute_reply.started":"2023-04-10T20:26:34.988536Z","shell.execute_reply":"2023-04-10T20:26:35.000996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nconfusion_matrix = metrics.confusion_matrix(yf_test, y_pred)\n\nplt.figure(figsize=(8,6))\nfx=sns.heatmap(confusion_matrix, annot=True, fmt=\".2f\",cmap=\"GnBu\")\nfx.set_title('Confusion Matrix \\n');\nfx.set_xlabel('\\n Predicted Values\\n')\nfx.set_ylabel('Actual Values\\n')\n#labels = ['Audio-Streaming','Browsing','Chat','Email','File-Transfer','P2P', 'Video-Streaming','VOIP']\nlabels = ['Benign', 'Malignant']\nfx.xaxis.set_ticklabels(labels, rotation=90)\nfx.yaxis.set_ticklabels(labels, rotation=0)\nplt.savefig('confusionmatrix.png', dpi = 300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:26:29.905444Z","iopub.execute_input":"2023-04-10T19:26:29.906921Z","iopub.status.idle":"2023-04-10T19:26:30.618894Z","shell.execute_reply.started":"2023-04-10T19:26:29.906853Z","shell.execute_reply":"2023-04-10T19:26:30.617943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#accuracy on test set\nesult = model.score(stackedX, yf_test)\nprint(\"Accuracy - test set: %.2f%%\" % (result*100.0))\n\n#precision on test set\nprecision = precision_score(yf_test, y_pred)\nprint('Precision: %f' % precision)\n\n# recall: tp / (tp + fn)\nrecall = recall_score(yf_test, y_pred)\nprint('Recall: %f' % recall)\n\n# f1: tp / (tp + fp + fn)\nf1 = f1_score(yf_test, y_pred)\nprint('F1 score: %f' % f1)\n\n# ROC curve\n# predict probabilities\nprobs = xgb.predict_proba(Xf_test)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n\nauc = roc_auc_score(yf_test, probs)\nprint('AUC - Test Set: %.2f%%' % (auc*100))\n\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(yf_test, probs)\n# plot no skill\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('False positive rate')\nplt.ylabel('Sensitivity/ Recall')\n#plt.savefig('auc_roc.png', dpi=300)\n# show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:26:51.872972Z","iopub.execute_input":"2023-04-10T19:26:51.873475Z","iopub.status.idle":"2023-04-10T19:26:52.099129Z","shell.execute_reply.started":"2023-04-10T19:26:51.873437Z","shell.execute_reply":"2023-04-10T19:26:52.097675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xf_test","metadata":{"execution":{"iopub.status.busy":"2023-04-10T20:33:59.08932Z","iopub.execute_input":"2023-04-10T20:33:59.08978Z","iopub.status.idle":"2023-04-10T20:33:59.111289Z","shell.execute_reply.started":"2023-04-10T20:33:59.089747Z","shell.execute_reply":"2023-04-10T20:33:59.109969Z"},"trusted":true},"execution_count":null,"outputs":[]}]}