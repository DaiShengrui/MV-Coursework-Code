{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1ed0e92",
   "metadata": {},
   "source": [
    "# CNN Dual Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43aa1c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.3182873995531172\n",
      "Test Accuracy: 76.94%\n",
      "Epoch 2/20, Loss: 0.4850076564720699\n",
      "Test Accuracy: 80.02%\n",
      "Epoch 3/20, Loss: 0.43210403337365105\n",
      "Test Accuracy: 80.36%\n",
      "Epoch 4/20, Loss: 0.4347768823305766\n",
      "Test Accuracy: 77.44%\n",
      "Epoch 5/20, Loss: 0.4110545785654159\n",
      "Test Accuracy: 72.70%\n",
      "Epoch 6/20, Loss: 0.44649588352157954\n",
      "Test Accuracy: 73.99%\n",
      "Epoch 7/20, Loss: 0.45241435936519075\n",
      "Test Accuracy: 81.11%\n",
      "Epoch 8/20, Loss: 0.501456754548209\n",
      "Test Accuracy: 78.46%\n",
      "Epoch 9/20, Loss: 0.45172365861279623\n",
      "Test Accuracy: 80.51%\n",
      "Epoch 10/20, Loss: 0.4404874075026739\n",
      "Test Accuracy: 81.68%\n",
      "Epoch 11/20, Loss: 0.3886911159469968\n",
      "Test Accuracy: 77.93%\n",
      "Epoch 12/20, Loss: 0.38471623119853793\n",
      "Test Accuracy: 71.14%\n",
      "Epoch 13/20, Loss: 0.3953280874661037\n",
      "Test Accuracy: 68.94%\n",
      "Epoch 14/20, Loss: 0.4463174641132355\n",
      "Test Accuracy: 67.27%\n",
      "Epoch 15/20, Loss: 0.42948812317280544\n",
      "Test Accuracy: 81.91%\n",
      "Epoch 16/20, Loss: 0.3699377406211126\n",
      "Test Accuracy: 79.26%\n",
      "Epoch 17/20, Loss: 0.36882964628083365\n",
      "Test Accuracy: 81.34%\n",
      "Epoch 18/20, Loss: 0.36896353534289766\n",
      "Test Accuracy: 81.76%\n",
      "Epoch 19/20, Loss: 0.39414202599298387\n",
      "Test Accuracy: 81.87%\n",
      "Epoch 20/20, Loss: 0.3699502923658916\n",
      "Test Accuracy: 81.72%\n",
      "Best model saved.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "# define double-convolutional neural networks\n",
    "class CNNWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNWithAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "        self.fc1 = nn.Linear(64, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        self.attention = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.max_pool(x)  # Add the maximum value pooling\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.max_pool(x)  # Add the maximum value pooling again\n",
    "        # Calculate the attention weights\n",
    "        attention_weights = torch.softmax(self.attention(x.mean(dim=(2, 3))), dim=1)\n",
    "        # Weighting average features using attention weights\n",
    "        x = (x * attention_weights.unsqueeze(2).unsqueeze(3)).sum(dim=(2, 3))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "class EnsembleCNN(nn.Module):\n",
    "    def __init__(self, num_networks=2):\n",
    "        super(EnsembleCNN, self).__init__()\n",
    "        self.num_networks = num_networks\n",
    "        self.networks = nn.ModuleList([CNNWithAttention() for _ in range(num_networks)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        predictions = torch.zeros(x.size(0), 2).to(x.device)  # Initialize the prediction results\n",
    "        for i in range(self.num_networks):\n",
    "            predictions += self.networks[i](x)  # Accumulate the prediction results for each network\n",
    "        predictions /= self.num_networks  # Take the average to get the final prediction result\n",
    "        return predictions\n",
    "\n",
    "# Load the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# Suppose the dataset is deposited in the data _ dir directory and contains two subfolders, malignant and benign, with images of malignant and benign tumors, respectively\n",
    "train_dir = \"archive/test\"\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dir = \"archive/train\"\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "# Divide between the training set and the test sets\n",
    "\n",
    "# Create the data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the model, the loss function, and the optimizer\n",
    "model = EnsembleCNN(num_networks=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "best_model_state_dict = model.state_dict()\n",
    "best_accuracy = 0.0\n",
    "# Training model\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "    # Assess the model on the test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        # If the current model has better accuracy than the previous highest accuracy, the state dictionary of the current model is saved\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model_state_dict = model.state_dict()\n",
    "\n",
    "# Model for saving the optimal parameters\n",
    "torch.save(best_model_state_dict, \"best_model.pth\")\n",
    "print(\"Best model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a4eee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.72%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60a30593",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"81.72%_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf831a7",
   "metadata": {},
   "source": [
    "# CRFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70f3ddcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Test Accuracy: 78.95%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "# Define double-convolutional neural networks\n",
    "class CNNWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNWithAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        self.attention = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.max_pool(x)  # Add the maximum value pooling\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.max_pool(x)  # Add the maximum value pooling again\n",
    "        # Calculate the attention weights\n",
    "        attention_weights = torch.softmax(self.attention(x.mean(dim=(2, 3))), dim=1)\n",
    "        # Weighting average features using attention weights\n",
    "        x = (x * attention_weights.unsqueeze(2).unsqueeze(3)).sum(dim=(2, 3))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class EnsembleCNNWithRandomForest(nn.Module):\n",
    "    def __init__(self, num_networks=2):\n",
    "        super(EnsembleCNNWithRandomForest, self).__init__()\n",
    "        self.num_networks = num_networks\n",
    "        self.networks = nn.ModuleList([CNNWithAttention() for _ in range(num_networks)])\n",
    "        self.random_forest = RandomForestClassifier(n_estimators=100)  # Random forest model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract the features of the deep learning model\n",
    "        features = []\n",
    "        for i in range(self.num_networks):\n",
    "            features.append(self.networks[i](x).detach().cpu().numpy())  # Disconnect the gradient flow using detach and transferred to the CPU\n",
    "        features = np.concatenate(features, axis=1)  # Splthe features into a matrix\n",
    "\n",
    "        return torch.tensor(features).to(x.device)\n",
    "# Load the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# Suppose the dataset is deposited in the data _ dir directory and contains two subfolders, malignant and benign, with images of malignant and benign tumors, respectively\n",
    "train_dir = \"archive/test\"\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dir = \"archive/train\"\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "# Divide between the training set and the test sets\n",
    "\n",
    "# Create the data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the model, the loss function, and the optimizer\n",
    "model = EnsembleCNNWithRandomForest(num_networks=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "best_model_state_dict = model.state_dict()\n",
    "best_accuracy = 0.0\n",
    "train_features = []\n",
    "train_labels = []\n",
    "for inputs, labels in train_loader:\n",
    "    features = model(inputs)\n",
    "    train_features.append(features)\n",
    "    train_labels.append(labels)\n",
    "train_features = torch.cat(train_features, dim=0).numpy()\n",
    "train_labels = torch.cat(train_labels, dim=0).numpy()\n",
    "\n",
    "# Training of the random forest model\n",
    "model.random_forest.fit(train_features, train_labels)\n",
    "\n",
    "# Prediction was made on the test set\n",
    "test_features = []\n",
    "for inputs, _ in test_loader:\n",
    "    features = model(inputs)\n",
    "    test_features.append(features)\n",
    "test_features = torch.cat(test_features, dim=0).numpy()\n",
    "\n",
    "predicted_labels = model.random_forest.predict(test_features)\n",
    "\n",
    "# Calculate the accuracy rate\n",
    "true_labels = torch.cat([labels for _, labels in test_loader], dim=0).numpy()\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Ensemble Model Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433f991",
   "metadata": {},
   "source": [
    "# CNN+RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ef7ed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 6.2908\n",
      "Epoch [2/10], Loss: 0.6683\n",
      "Epoch [3/10], Loss: 0.4830\n",
      "Epoch [4/10], Loss: 0.5070\n",
      "Epoch [5/10], Loss: 0.4956\n",
      "Epoch [6/10], Loss: 0.4517\n",
      "Epoch [7/10], Loss: 0.6107\n",
      "Epoch [8/10], Loss: 0.5263\n",
      "Epoch [9/10], Loss: 0.4820\n",
      "Epoch [10/10], Loss: 0.4334\n",
      "Ensemble Model Test Accuracy: 76.26%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import transforms, datasets\n",
    "# Define the convolutional neural networks\n",
    "class CNNWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNWithAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        self.attention = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.max_pool(x)  # Add the maximum value pooling\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.max_pool(x)  # Add the maximum value pooling again\n",
    "        # Calculate the attention weights\n",
    "        attention_weights = torch.softmax(self.attention(x.mean(dim=(2, 3))), dim=1)\n",
    "        # Weighting average features using attention weights\n",
    "        x = (x * attention_weights.unsqueeze(2).unsqueeze(3)).sum(dim=(2, 3))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class EnsembleCNNWithRandomForest(nn.Module):\n",
    "    def __init__(self, num_networks=2):\n",
    "        super(EnsembleCNNWithRandomForest, self).__init__()\n",
    "        self.num_networks = num_networks\n",
    "        self.networks = nn.ModuleList([CNNWithAttention() for _ in range(num_networks)])\n",
    "        self.random_forest = RandomForestClassifier(n_estimators=100)  # Random forest model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract the features of the deep learning model\n",
    "        features = []\n",
    "        for i in range(self.num_networks):\n",
    "            features.append(self.networks[i](x))\n",
    "        features = torch.cat(features, dim=1)  # Features the features into one Tensor\n",
    "\n",
    "        return features\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# Load the dataset\n",
    "# ...\n",
    "# Suppose the dataset is deposited in the data _ dir directory and contains two subfolders, malignant and benign, with images of malignant and benign tumors, respectively\n",
    "train_dir = \"archive/test\"\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dir = \"archive/train\"\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "# Divide between the training set and the test sets\n",
    "\n",
    "# Create the data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Create the EnsembleCNNWithRandomForest model\n",
    "ensemble_model = EnsembleCNNWithRandomForest(num_networks=2)\n",
    "\n",
    "# Training of the convolutional neural network model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ensemble_model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ensemble_model.train()\n",
    "    total_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ensemble_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")\n",
    "\n",
    "# Obtain features of the deep learning model as input\n",
    "train_features = []\n",
    "train_labels = []\n",
    "for inputs, labels in train_loader:\n",
    "    features = ensemble_model(inputs)\n",
    "    train_features.append(features)\n",
    "    train_labels.append(labels)\n",
    "train_features = torch.cat(train_features, dim=0).detach().numpy()\n",
    "train_labels = torch.cat(train_labels, dim=0).detach().numpy()\n",
    "\n",
    "# Training of the random forest model\n",
    "ensemble_model.random_forest.fit(train_features, train_labels)\n",
    "\n",
    "# Prediction was made on the test set\n",
    "test_features = []\n",
    "for inputs, _ in test_loader:\n",
    "    features = ensemble_model(inputs)\n",
    "    test_features.append(features)\n",
    "test_features = torch.cat(test_features, dim=0).detach().numpy()\n",
    "\n",
    "predicted_labels = ensemble_model.random_forest.predict(test_features)\n",
    "\n",
    "# Calculate the accuracy rate\n",
    "true_labels = torch.cat([labels for _, labels in test_loader], dim=0).numpy()\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Ensemble Model Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
